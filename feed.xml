<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://ordina-jworks.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ordina-jworks.github.io/" rel="alternate" type="text/html" /><updated>2023-05-18T11:46:18+00:00</updated><id>https://ordina-jworks.github.io/feed.xml</id><title type="html">Ordina JWorks Tech Blog</title><subtitle>We build innovative solutions with Java and JavaScript. To support this mission, we have several Competence Centers. From within those Competence Centers, we provide coaching to the employee and expert advice towards our customer. In order to keep in sync with the latest technologies and the latest trends, we frequently visit conferences around the globe.
</subtitle><entry><title type="html">KubeCon + CloudNativeCon 2023</title><link href="https://ordina-jworks.github.io/cloud/2023/05/17/kubecon-2023.html" rel="alternate" type="text/html" title="KubeCon + CloudNativeCon 2023" /><published>2023-05-17T00:00:00+00:00</published><updated>2023-05-17T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/cloud/2023/05/17/kubecon-2023</id><content type="html" xml:base="https://ordina-jworks.github.io/cloud/2023/05/17/kubecon-2023.html"><![CDATA[<h1 id="introduction">Introduction</h1>

<p style="text-align: center;"><img src="/img/2023-05-17-kubecon-2023/group-picture.jpg" alt="JWorks group picture" class="image" style="margin:0px auto; max-width:100%" />
<em>JWorks at Kubecon 2023</em></p>

<p>Another year, another KubeCon | CloudNativeCon EU edition. 
And, of course, JWorks was also present at this year’s edition in Amsterdam in the <a href="https://www.rai.nl/" target="_blank" rel="noopener noreferrer">RAI</a>.
We wanted to hear more about all the new features, frameworks, tools, ideas and concepts that the Kubernetes and cloud world have to offer.
And we got what we wanted.
We attended many interesting talks, talked to very intriguing people at the event, and had a lot of fun while doing so.
Next to the talks, there were also many booths from companies from all over the world (AWS, Azure, Canonical, …) to engage with other people and to talk and promote their newest products for the developer market.
You can look at some of the talks we attended, which were very interesting.
You can click on the talk title to go to the recorded version on YouTube, which CNCF provides.</p>

<h1 id="metrics-at-full-throttle-intro-and-deep-dive-into-thanos---saswata-mukherjee--filip-petkovski-shopify"><a href="https://www.youtube.com/watch?v=2GokLB5_VfY" target="_blank" rel="noopener noreferrer">Metrics at Full Throttle: Intro and Deep Dive Into Thanos - Saswata Mukherjee &amp; Filip Petkovski, Shopify</a></h1>

<p><a href="https://thanos.io/" target="_blank" rel="noopener noreferrer">Thanos</a> enables a highly available Prometheus setup.
It replaces parts of the Prometheus deployment model that are hard to scale with regular Prometheus.</p>

<p>This talk is a great introduction to Thanos.
Saswata and Filip start by explaining what difficulties you can have with scaling a regular Prometheus setup. 
They explain what components of Thanos solve the different issues with scaling Prometheus. 
The following components of Thanos are introduced: Sidecar, Ruler, Receive, Query, Compactor, and Store gateway.</p>

<p>Where the first half of the talk is mainly targeted towards people who don’t know Thanos or don’t know all capabilities of Thanos yet, the second half was surely targeted towards experienced Thanos users.
In the second half of the talk, Saswata and Filip highlight recent, since the KubeCon Detroit, improvements to Thanos.</p>

<p>They discuss 5 new features in Thanos. 
The first boils down to optimizations to the store gateway to remove the high IO requirements to run the store gateway.
The new store gateway implementation doesn’t require the high IO disk anymore as the information is stored in memory instead of on disk.</p>

<p>Three new features were announced to optimize the querying throughout the different components in Thanos.</p>

<p>First, quality of service limits was added as Thanos configuration options. 
This allows teams managing Thanos to define the limits to tune the Thanos performance and prevent a single query from overloading the system.</p>

<p>The second improvement related to query performance was a newly implemented, Thanos-specific, PromQL engine. 
With the new query engine, the query will be analyzed up front and an optimal (parallel!) execution will be determined. 
Since not all operators are supported yet, the new engine will be used when possible with a fallback to the standard Prometheus PromQL engine when needed.</p>

<p>The third improvement is the distributed execution of queries.
This mechanism allows queries to be executed by the nodes that have direct access to the needed data, preventing costly data transfers between components in the Thanos architecture. 
If you want more information on this amazing feature, definitely check out this talk when it’s available on YouTube!</p>

<p>A new hash ring mechanism was implemented for the Receiver to prevent overloading single Receiver instances.</p>

<p>They end by showing real-world performance graphs from a Thanos deployment and how different versions of Thanos caused visible improvements.</p>

<h1 id="playstation-and-kubernetes-how-to-solve-a-problem-like-real-time---joseph-irving-playstation"><a href="https://www.youtube.com/watch?v=pklRTQoRrNY" target="_blank" rel="noopener noreferrer">PlayStation and Kubernetes: How to Solve a Problem Like Real-Time - Joseph Irving, PlayStation</a></h1>

<p>Since its birth in 1994, (Sony) PlayStation has been a global pioneer in the gaming industry.
As PlayStation grew, its infrastructure needed to grow as well.
Over time, PlayStation had to scale its game servers so that it could handle their demand.
This had to be done in a way where game servers could be scaled in a compatible way with the game clients.
This means that simply spinning up more instances of the game server might not always work.</p>

<p>This talk, presented by Joseph Irving, went over the kind of problems they faced, different types of real-time game servers, and their advantages and limitations (peer-to-peer, dedicated game servers, etc.).</p>

<p>Their solution was to use a project called <a href="https://agones.dev/site/" target="_blank" rel="noopener noreferrer">Agones</a>, which is created and maintained by Google in collaboration with Ubisoft.
Agones is an open-source platform that provides a native way of running game servers on Kubernetes without worrying about the infrastructure.
It provides compatibility with game server connections by using GameServers and connecting those GameServers with Fleets.
Joseph introduces the Agones framework and talks about how they use it and how it helped them to scale their gaming servers and to provide multi-regional operability.</p>

<p>He concludes the talk by talking about Matchmakers, which implements matchmaking (finding matches for people that are searching for a lobby in a game) through Kubernetes.</p>

<h1 id="automating-configuration-and-permissions-testing-for-gitops-with-opa-conftest---eve-ben-ezra--michael-hume-the-new-york-times"><a href="https://www.youtube.com/watch?v=VCX4UALQjeg" target="_blank" rel="noopener noreferrer">Automating Configuration and Permissions Testing for GitOps with OPA Conftest - Eve Ben Ezra &amp; Michael Hume, The New York Times</a></h1>

<p>Open Policy Agent is a tool to add <a href="https://www.openpolicyagent.org/" target="_blank" rel="noopener noreferrer">policy-based control to cloud-native environments</a>.
OPA is used in many different tools and systems as a system to validate configuration before it’s deployed to cloud environments.</p>

<p>In this talk, Eve and Michel explain how OPA is used in the New York Times internal developer platform to control what their developers deploy.
Eve starts by showing what problems they experienced at the New York Times with allowing developers to use the internal platform. 
As with all validation (aka testing) mechanisms, shifting left is the focus. 
They continue to explain how <a href="https://www.conftest.dev/" target="_blank" rel="noopener noreferrer">Conftest</a> helped them in providing feedback to the developer as soon as they write a single line of code.
Validating the configuration using the same definition along every set in the process, makes it very transparent to developers where issues are introduced and what they can do to fix them.</p>

<p>Next, a great introduction to OPAs rule language Rego is shown by Eve.
They take the audience through a complete example, explaining what is defined and how it’s interpreted, including the quirks, using Rego.</p>

<p>Finally, Michel shows how <a href="https://github.com/yannh/kubeconform" target="_blank" rel="noopener noreferrer">Kubeconform</a> can be used to help with Kubernetes version migrations, including CRDs. 
They show a real example and explain how the output of the tool can be used to quickly identify what’s wrong with a manifest.</p>

<p>If anything, this talk is a brilliant introduction to Rego.
If you have an interest in policy management in your Kubernetes cluster or if you have experienced hard-to-find bugs in Kubernetes manifests, this is a must-watch talk from the <a href="https://www.nytimes.com/" target="_blank" rel="noopener noreferrer">New York Times</a>.</p>

<h1 id="state-of-the-mop-cloud-custodian-in-2023"><a href="https://www.youtube.com/watch?v=Lx5f-0WOFrA" target="_blank" rel="noopener noreferrer">State of the Mop: Cloud Custodian in 2023</a></h1>

<p>During the presentation, Kapil Thangavelu provided a concise update on <a href="https://cloudcustodian.io/" target="_blank" rel="noopener noreferrer">Cloud Custodian</a>, an open-source rules engine designed for account and resource management on AWS, Azure, and GCP, based on the Rego language.
Cloud Custodian can effectively scale from small businesses to large enterprises.</p>

<p>Since Kubecon Detroit in October 2022, Cloud Custodian has added support for two new providers.
Additionally, they’ve included Terraform support to enable users to check their Terraform source code while running inside a pipeline.</p>

<p>Looking ahead, Cloud Custodian’s roadmap for the current year includes adding a new K8s admission controller, support for AWS CloudFormation, preventative support for AWS, and an improved authoring experience through the addition of policy testing, policy tracing, a policy debugger, and more.</p>

<p>Cloud Custodian’s open-source nature, flexibility, and upcoming roadmap make it a tool to watch for organizations managing cloud resources.
It provides a powerful and customizable way to improve security, cost optimization, and compliance across different cloud providers.</p>

<h1 id="scaling-databases-at-activision---greg-smith--vladimir-kovacik-activisionblizzard"><a href="https://www.youtube.com/watch?v=_ba9tbivT28" target="_blank" rel="noopener noreferrer">Scaling Databases at Activision - Greg Smith &amp; Vladimir Kovacik, Activision/Blizzard</a></h1>
<p>This talk goes over how Activision / Blizzard scaled their databases over time. 
They introduce the session by talking about hosting and operating their databases in the past, which included bare metal, many virtual machines &amp; containers, …
As they progressed and more people joined their games (especially on launch days), they quickly discovered that there was a need for better scaling, especially in the number of shards, due to performance issues.</p>

<p>As the whole company was internally moving to Kubernetes, they wondered if there was a way to have their MySQL databases hosted on Kubernetes natively. 
This is where they introduce <a href="https://vitess.io/" target="_blank" rel="noopener noreferrer">Vitess</a>, a native way to run and scale MySQL-compatible databases.
They wanted to use something that supported MySQL since they had plenty of MySQL experts employed and because they used MySQL before adopting Vitess.</p>

<p>They divided the migration to Vitess into three adoption stages: MVP, Load Testing &amp; Production Readiness.</p>

<h3 id="mvp">MVP</h3>
<p>In the MVP stage, they wanted to find out how easy or hard it was to migrate to Vitess. 
They needed to verify that Vitess works for them, which they could quickly find out by running their database tests.
Along the way, they were able to fix all the issues that the migration caused, which included talking with the Vitess community to find solutions.</p>

<h3 id="load-testing">Load Testing</h3>
<p>In the Load Testing stage, they needed to make sure that this new solution was able to scale successfully and handle their workload (again, especially on launch days).
This could be done by checking if shards scaled successfully and that there were no performance bottlenecks during the load testing.
The developers were able to confirm that scaling was done as how they expected it to scale.</p>

<h3 id="production-readiness">Production Readiness</h3>
<p>In the Production Readiness stage, they had to prove that their solution worked and that their previous stage turned out as a success.
However, they wanted more confirmation about how Vitess works as they needed to be sure that it was the right solution.
After some chaos testing and implementing other Vitess features, they confirmed that the scaling solution was stable.</p>

<p>One of their most important changes was the move from application sharding to a single endpoint.
Where there previously was a separate sharding configuration in the application configuration, they now moved to a single database endpoint.</p>

<p>They concluded the talk by stating that Vitess does work, and right now there are approximately 60 Vitess clusters in development and production environments.
They are also building an internal team around the company to support Vitess, and it has become the default database solution for any new services that the company will implement.</p>

<p>It was a very long process, but eventually, they were able to successfully adopt Vitess.</p>

<h1 id="sponsors--vendors--projects-with-stands">Sponsors / Vendors / Projects with stands</h1>
<p>At Kubecon, there were a lot of booths where companies and separate projects were able to promote their product, introduce new features, and offer some fun gadgets to the attendees of Kubecon.
Some major players in the industry were there, and of course, a lot of people were interested in what they had to offer to make their lives more simple.</p>

<h2 id="aws">AWS</h2>

<p>AWS had an impressive presence, offering attendees a wide range of experiences and insights into their latest developments.
The AWS stand provided a sneak peek of upcoming features and integrations planned for their EKS portal.
The visuals on display highlighted their focus on monitoring and improving the overall user experience.</p>

<p>In addition to the exciting demos, AWS provided a fun and challenging mini-golf game for conference-goers to play.
Participants had the opportunity to win AWS-branded pyjama pants, adding a touch of fun and excitement to the event.</p>

<p>AWS didn’t stop at the game, as they also offered an array of other goodies for attendees throughout the conference.
Whether it was swag bags or other branded merchandise, AWS had something for everyone.</p>

<p>Finally, AWS brought a team of experts who were available to answer any questions attendees had about EKS.
Their knowledgeable team provided attendees with valuable insights and guidance on using the platform effectively.</p>

<h1 id="conclusion">Conclusion</h1>
<p>Kubecon was a fun experience, and we got a load of interesting topics and talks.
Amsterdam is beautiful and tourist-friendly, with most of the residents speaking English fluently.
The RAI was a huge venue, which meant to go from talk to talk some (power) walking was needed.
Some talks were too popular to fit into the rooms that were assigned to them.
The live stream was always a backup, but it doesn’t have that same effect, even if you sit around a smartphone screen with ten people to watch a talk.
The food and especially the coffee was great this edition.
KubeCon | CloudNativeCon EU was a great experience, and we can’t wait until next year’s edition.
See you in Paris!</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Yolan&quot;, &quot;last_name&quot;=&gt;&quot;Vloeberghs&quot;, &quot;linkedin&quot;=&gt;&quot;yolan-vloeberghs-23825aa3&quot;, &quot;github&quot;=&gt;&quot;yolanv&quot;, &quot;permalink&quot;=&gt;&quot;/author/yolan-vloeberghs/&quot;, &quot;avatar&quot;=&gt;&quot;yolan-vloeberghs.jpg&quot;, &quot;title&quot;=&gt;&quot;Java Consultant&quot;, &quot;email&quot;=&gt;&quot;yolan.vloeberghs@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Yolan Vloeberghs is a Java and Cloud engineer with a sharpened focus on all things related to cloud, specifically AWS. He loves to play around with various technologies and frameworks and is very passionated and eager to learn about everything related to cloud-native development.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2019-04-02-Kickstarter-Trajectory-2019-Light.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-07-10-Spring-IO-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-08-05-deploy-spring-boot-kubernetes.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-29-AWS-Dev-Day-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-05-07-jib.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-08-28-kubernetes-clients-comparison.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-12-10-aws-fargate-serverless-deployments.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-11-03-selenium-e2e-testing.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-06-13-aws-rds-iam-authentication-spring-boot.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-01-13-aws-lambda-snapstart-spring-cloud-function.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-05-17-kubecon-2023.md collection=posts&gt;]}</name><email>yolan.vloeberghs@ordina.be</email></author><category term="Cloud" /><category term="cloud" /><category term="conference" /><category term="cloud-native" /><category term="kubernetes" /><summary type="html"><![CDATA[Introduction]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2023-05-17-kubecon-2023/banner-resized.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2023-05-17-kubecon-2023/banner-resized.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Date and Time Testing</title><link href="https://ordina-jworks.github.io/testing/2023/04/28/date-time-testing.html" rel="alternate" type="text/html" title="Date and Time Testing" /><published>2023-04-28T00:00:00+00:00</published><updated>2023-04-28T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/testing/2023/04/28/date-time-testing</id><content type="html" xml:base="https://ordina-jworks.github.io/testing/2023/04/28/date-time-testing.html"><![CDATA[<p>Working with dates and times can be challenging for developers, especially regarding testing.
When testing code that involves the current date or time, it takes time to ensure that the results are correct and consistent.
Luckily, there are several ways to solve this problem.</p>

<p>One approach is to use a fixed date and time in your tests.
This ensures that your code produces consistent results, regardless of the actual date and time.
You can achieve this by mocking the <code class="language-plaintext highlighter-rouge">now()</code> method of the <code class="language-plaintext highlighter-rouge">LocalDateTime</code> class, which returns the current date and time.</p>

<p>Here’s an example of how to mock the <code class="language-plaintext highlighter-rouge">now()</code> method of the <code class="language-plaintext highlighter-rouge">LocalDateTime</code> class using Mockito Inline and Java:</p>

<pre><code class="language-pom.xml">&lt;dependency&gt;
    &lt;groupId&gt;org.mockito&lt;/groupId&gt;
    &lt;artifactId&gt;mockito-inline&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span> <span class="o">(</span><span class="nc">MockedStatic</span><span class="o">&lt;</span><span class="nc">LocalDateTime</span><span class="o">&gt;</span> <span class="n">mockedStatic</span> <span class="o">=</span> <span class="nc">Mockito</span><span class="o">.</span><span class="na">mockStatic</span><span class="o">(</span><span class="nc">LocalDateTime</span><span class="o">.</span><span class="na">class</span><span class="o">))</span> <span class="o">{</span>
    <span class="n">mockedStatic</span><span class="o">.</span><span class="na">when</span><span class="o">(</span><span class="nl">LocalDateTime:</span><span class="o">:</span><span class="n">now</span><span class="o">).</span><span class="na">thenReturn</span><span class="o">(</span><span class="n">fixedDate</span><span class="o">);</span>

    <span class="c1">// Your code here.</span>
<span class="o">}</span>
</code></pre></div></div>

<p>In this code snippet, <code class="language-plaintext highlighter-rouge">fixedDate</code> is a <code class="language-plaintext highlighter-rouge">LocalDateTime</code> object representing the fixed date and time you want to use in your tests.
The <code class="language-plaintext highlighter-rouge">MockedStatic</code> class is a Mockito class that allows you to mock static methods.</p>

<p>To make this code more reusable, you can create a small method that accepts a <code class="language-plaintext highlighter-rouge">fixedDate</code> and a test in a <code class="language-plaintext highlighter-rouge">Runnable</code>.
This will help to improve your code significantly and make it more readable:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">private</span> <span class="kt">void</span> <span class="nf">tryOn</span><span class="o">(</span><span class="nc">LocalDateTime</span> <span class="n">fixedDate</span><span class="o">,</span> <span class="nc">Runnable</span> <span class="n">test</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">try</span> <span class="o">(</span><span class="nc">MockedStatic</span><span class="o">&lt;</span><span class="nc">LocalDateTime</span><span class="o">&gt;</span> <span class="n">mockedStatic</span> <span class="o">=</span> <span class="nc">Mockito</span><span class="o">.</span><span class="na">mockStatic</span><span class="o">(</span><span class="nc">LocalDateTime</span><span class="o">.</span><span class="na">class</span><span class="o">))</span> <span class="o">{</span>
        <span class="n">mockedStatic</span><span class="o">.</span><span class="na">when</span><span class="o">(</span><span class="nl">LocalDateTime:</span><span class="o">:</span><span class="n">now</span><span class="o">).</span><span class="na">thenReturn</span><span class="o">(</span><span class="n">fixedDate</span><span class="o">);</span>
        <span class="n">test</span><span class="o">.</span><span class="na">run</span><span class="o">();</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>You can then use this method in your tests to ensure that your code produces consistent results:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tryOn</span><span class="o">(</span><span class="n">fixedDate</span><span class="o">,</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
    <span class="c1">// Your code here.</span>
<span class="o">});</span>
</code></pre></div></div>

<p>Using a fixed date and time in your tests ensures that your code produces consistent results, regardless of the actual date and time.
This can help you to identify and fix bugs more quickly and ensure that your code works as expected in all scenarios.</p>

<p>In summary, when testing code that involves the current date and time, it’s essential to use a fixed date and time to ensure consistent results.
You can achieve this by mocking the <code class="language-plaintext highlighter-rouge">now()</code> method of the <code class="language-plaintext highlighter-rouge">LocalDateTime</code> class using Mockito and Java.
By using a small method like <code class="language-plaintext highlighter-rouge">tryOn</code>, you can make your code more reusable and easier to read.</p>

<p>A full code example</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">static</span> <span class="n">org</span><span class="o">.</span><span class="na">assertj</span><span class="o">.</span><span class="na">core</span><span class="o">.</span><span class="na">api</span><span class="o">.</span><span class="na">Assertions</span><span class="o">.</span><span class="na">assertThat</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.time.LocalDate</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.junit.jupiter.api.Test</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.mockito.MockedStatic</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.mockito.Mockito</span><span class="o">;</span>

<span class="kd">class</span> <span class="nc">AgeCalculatorTest</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="nc">LocalDate</span> <span class="no">APRIL_27_2023</span> <span class="o">=</span> <span class="nc">LocalDate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="mi">2023</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">27</span><span class="o">);</span>
    
    <span class="nd">@Test</span>
    <span class="kt">void</span> <span class="nf">testCalculateAgeWorksOnlyIn2023</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// Arrange</span>
        <span class="nc">LocalDate</span> <span class="n">birthDate</span> <span class="o">=</span> <span class="nc">LocalDate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="mi">1993</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">27</span><span class="o">);</span>

        <span class="c1">// Act</span>
        <span class="kt">int</span> <span class="n">actualAge</span> <span class="o">=</span> <span class="nc">AgeCalculator</span><span class="o">.</span><span class="na">calculateAge</span><span class="o">(</span><span class="n">birthDate</span><span class="o">);</span>

        <span class="c1">// Assert</span>
        <span class="kt">int</span> <span class="n">expectedAge</span> <span class="o">=</span> <span class="mi">30</span><span class="o">;</span>
        <span class="n">assertThat</span><span class="o">(</span><span class="n">actualAge</span><span class="o">).</span><span class="na">isEqualTo</span><span class="o">(</span><span class="n">expectedAge</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Test</span>
    <span class="kt">void</span> <span class="nf">testCalculateAgeWorksEveryYear</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// Arrange</span>
        <span class="kd">final</span> <span class="nc">LocalDate</span> <span class="n">birthDate</span> <span class="o">=</span> <span class="nc">LocalDate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="mi">1993</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">27</span><span class="o">);</span>

        <span class="k">try</span> <span class="o">(</span><span class="nc">MockedStatic</span><span class="o">&lt;</span><span class="nc">LocalDate</span><span class="o">&gt;</span> <span class="n">mockedStatic</span> <span class="o">=</span> <span class="nc">Mockito</span><span class="o">.</span><span class="na">mockStatic</span><span class="o">(</span><span class="nc">LocalDate</span><span class="o">.</span><span class="na">class</span><span class="o">))</span> <span class="o">{</span>
            <span class="n">mockedStatic</span><span class="o">.</span><span class="na">when</span><span class="o">(</span><span class="nl">LocalDate:</span><span class="o">:</span><span class="n">now</span><span class="o">).</span><span class="na">thenReturn</span><span class="o">(</span><span class="no">APRIL_27_2023</span><span class="o">);</span>

            <span class="c1">// Act</span>
            <span class="kt">int</span> <span class="n">actualAge</span> <span class="o">=</span> <span class="nc">AgeCalculator</span><span class="o">.</span><span class="na">calculateAge</span><span class="o">(</span><span class="n">birthDate</span><span class="o">);</span>

            <span class="c1">// Assert</span>
            <span class="kt">int</span> <span class="n">expectedAge</span> <span class="o">=</span> <span class="mi">30</span><span class="o">;</span>
            <span class="n">assertThat</span><span class="o">(</span><span class="n">actualAge</span><span class="o">).</span><span class="na">isEqualTo</span><span class="o">(</span><span class="n">expectedAge</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="nd">@Test</span>
    <span class="kt">void</span> <span class="nf">testCalculateAgeWorksEveryYearUsingTryOn</span><span class="o">()</span> <span class="o">{</span>
        <span class="c1">// Arrange</span>
        <span class="kd">final</span> <span class="nc">LocalDate</span> <span class="n">birthDate</span> <span class="o">=</span> <span class="nc">LocalDate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="mi">1993</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">27</span><span class="o">);</span>

        <span class="n">tryOn</span><span class="o">(</span><span class="no">APRIL_27_2023</span><span class="o">,</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="c1">// Act</span>
            <span class="kt">int</span> <span class="n">actualAge</span> <span class="o">=</span> <span class="nc">AgeCalculator</span><span class="o">.</span><span class="na">calculateAge</span><span class="o">(</span><span class="n">birthDate</span><span class="o">);</span>

            <span class="c1">// Assert</span>
            <span class="kt">int</span> <span class="n">expectedAge</span> <span class="o">=</span> <span class="mi">30</span><span class="o">;</span>
            <span class="n">assertThat</span><span class="o">(</span><span class="n">actualAge</span><span class="o">).</span><span class="na">isEqualTo</span><span class="o">(</span><span class="n">expectedAge</span><span class="o">);</span>
        <span class="o">});</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">tryOn</span><span class="o">(</span><span class="nc">LocalDate</span> <span class="n">fixedDate</span><span class="o">,</span> <span class="nc">Runnable</span> <span class="n">test</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">try</span> <span class="o">(</span><span class="nc">MockedStatic</span><span class="o">&lt;</span><span class="nc">LocalDate</span><span class="o">&gt;</span> <span class="n">mockedStatic</span> <span class="o">=</span> <span class="nc">Mockito</span><span class="o">.</span><span class="na">mockStatic</span><span class="o">(</span><span class="nc">LocalDate</span><span class="o">.</span><span class="na">class</span><span class="o">))</span> <span class="o">{</span>
            <span class="n">mockedStatic</span><span class="o">.</span><span class="na">when</span><span class="o">(</span><span class="nl">LocalDate:</span><span class="o">:</span><span class="n">now</span><span class="o">).</span><span class="na">thenReturn</span><span class="o">(</span><span class="n">fixedDate</span><span class="o">);</span>

            <span class="n">test</span><span class="o">.</span><span class="na">run</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="kd">static</span> <span class="kd">class</span> <span class="nc">AgeCalculator</span> <span class="o">{</span>

        <span class="kd">public</span> <span class="kd">static</span> <span class="kt">int</span> <span class="nf">calculateAge</span><span class="o">(</span><span class="nc">LocalDate</span> <span class="n">birthDate</span><span class="o">)</span> <span class="o">{</span>
            <span class="nc">LocalDate</span> <span class="n">currentDate</span> <span class="o">=</span> <span class="nc">LocalDate</span><span class="o">.</span><span class="na">now</span><span class="o">();</span>
            <span class="kt">int</span> <span class="n">age</span> <span class="o">=</span> <span class="n">currentDate</span><span class="o">.</span><span class="na">getYear</span><span class="o">()</span> <span class="o">-</span> <span class="n">birthDate</span><span class="o">.</span><span class="na">getYear</span><span class="o">();</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">birthDate</span><span class="o">.</span><span class="na">getDayOfYear</span><span class="o">()</span> <span class="o">&gt;</span> <span class="n">currentDate</span><span class="o">.</span><span class="na">getDayOfYear</span><span class="o">())</span> <span class="o">{</span>
                <span class="n">age</span><span class="o">--;</span>
            <span class="o">}</span>
            <span class="k">return</span> <span class="n">age</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Maarten&quot;, &quot;last_name&quot;=&gt;&quot;Casteels&quot;, &quot;permalink&quot;=&gt;&quot;/author/maarten-casteels/&quot;, &quot;avatar&quot;=&gt;&quot;maarten-casteels.png&quot;, &quot;title&quot;=&gt;&quot;Practice Lead Application Development&quot;, &quot;github&quot;=&gt;&quot;denmette&quot;, &quot;linkedin&quot;=&gt;&quot;maartencasteels&quot;, &quot;email&quot;=&gt;&quot;Maarten.Casteels@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Meet Maarten Casteels, a Practice Lead for Application Development at JWorks. With a passion for testing, he ensures that every code he creates is thoroughly tested before release. Outside of work, Maarten actively loves to bring people together.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2018-12-17-Devoxx-MA.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-04-28-date-time-testing.md collection=posts&gt;]}</name><email>Maarten.Casteels@ordina.be</email></author><category term="Testing" /><category term="testing" /><category term="unit testing" /><summary type="html"><![CDATA[Working with dates and times can be challenging for developers, especially regarding testing. When testing code that involves the current date or time, it takes time to ensure that the results are correct and consistent. Luckily, there are several ways to solve this problem.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2023-04-28-date-time-testing/blog-post-overlay.webp" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2023-04-28-date-time-testing/blog-post-overlay.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Intelligent Automation</title><link href="https://ordina-jworks.github.io/architecture/2023/02/20/intelligent-automation.html" rel="alternate" type="text/html" title="Intelligent Automation" /><published>2023-02-20T00:00:00+00:00</published><updated>2023-02-20T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/architecture/2023/02/20/intelligent-automation</id><content type="html" xml:base="https://ordina-jworks.github.io/architecture/2023/02/20/intelligent-automation.html"><![CDATA[<p>Already 4 years ago, <a href="https://evolute.be/reviews/bpmnext2019.html" target="_blank" rel="noopener noreferrer">Nathaniel Palmer’s keynote at bpmNext</a> introduced me to the concept of Intelligent Automation. 
This is the extension of the classical Process Management approach using Intelligent Business Process Management Solutions (iBPMS) to automate processes with the influx of new possibilities on a technological level: AI and machine learning to crunch the data, RPA, and the introduction of bots for automating swivel chair processes, and more pronounced use of decision management automation. 
When the <a href="https://bpm-books.com/products/intelligent-automation" target="_blank" rel="noopener noreferrer">titular book</a> was published by Future Strategies, I picked up my copy and started reading in the hopes of figuring out how to implement this. 
The book is similar in structure to other volumes of Future Strategies in that it is a collection of articles by luminaries in the field, accompanied by several award-winning case studies.</p>

<p>Not that the rise in importance of technologies such as AI should come as a surprise. 
Going back to 2016 the Artificial Intelligence Information Society as well as the World Bank offered up this infographic showing AI to be considered the 4th industrial revolution to shape our society.</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/industrialrevolutions.jpg" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<p>The questions that this new approach tries to answer rise from the underlying mismatch of traditional process automation with the current reality within organizations:</p>
<ol>
  <li>Process Modelling is still programming and thus does not alleviate the workload of the scarce resource that are developers.</li>
  <li>Office workplaces are no longer so static that they can easily be contained in a process model.</li>
  <li>Case Management Modeling Notation (CMMN) cannot fully answer this dynamic workplace either.</li>
  <li>Processes do not lend themselves naturally to a centralized consistent view of the organization.</li>
  <li>Maintaining the agreement on an agreed-upon process over time is difficult.</li>
</ol>

<p>Intelligent Automation is one of the latest attempts to efficiently answer digital disruption. 
This disruption is brought about by new technologies that emerge and upset the balance of any business ecosystem. 
We need to answer it with a digital transformation of the current landscape in organizations, and intelligent automation aims for this lofty goal by enhancing the traditional business process management discipline with process automation technology, guided by business rules and bots (both RPA and AI). 
The way to successfully monitor whether the path taken will lead to success is to oversee this process automation with the proper information governance.</p>

<p>Intelligent Automation thus plays on at least four aspects of the organization:</p>
<ol>
  <li>Adding intelligence to (operational) processes.</li>
  <li>Augmenting decision-making within a process through analytics.</li>
  <li>Monitoring processes for correct operation and adapting them to meet changes in the strategic or tactical direction of the organization.</li>
  <li>Applying intelligent automation and analytics to strategic and tactical decision-making.</li>
</ol>

<p>The introduction of bots on top of the typical iBPMS is rooted in the idea that human interaction in processes is still needed at certain times, and if our RPA bots can use the same interfaces as their human counterparts, there would be an efficiency gain by alleviated work from knowledge workers and a cost gain by eliminating the need to implement specific interfaces for these bots. 
It is however imperative that these bots know exactly what to do, and thus the same rules that guide human participants in the process need to apply to these bots. 
In addition to this, the same level of transparency (such as for audit or privacy purposes) should also apply to the bots. 
This way correct optimization of the process automation can be determined.</p>

<p>These different components are aptly assembled in Nathaniel Palmer’s vision for future process automation solutions:</p>
<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/ibpms.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<p>The three guiding principles are Rules, Robots, and Relationships. 
The Robot part of the equation was already tackled earlier in this post. 
The Relationship part focuses mainly on the data used in the processes. 
There is a shift here from the problems of storing and replication data locally towards the problems of where to get data in the wide world. 
The different pieces of the information puzzle could be spread across dozens of repositories all over the world, and although our complete information metamodel still exists, its parts need to be fetched from each of these repositories to complete any sort of 360° view.</p>

<p>Rules are formed by automating decisions and letting AI solutions approach the available information with machine learning to perform both analytical and predictive analyses. 
This isn’t magic, however, and these AI need to be properly trained using historical data to perform with any level of adequacy. 
These bots were dubbed probabilistic as opposed to the deterministic nature of RPA bots.</p>

<p>With all these different angles to process automation, it might look like a mire of patchwork islands. 
But this is where the traditional iBPMS excels, bridging these islands to arrive at an end-to-end process, managing the sequencing, and overseeing the state of running processes. 
This eventually leads to the promise of intelligent automation: Expanding the efficiency of automation while delivering greater transparency and policy compliance. 
And herein lies the business value of this proposition. 
If traditional BPMS automation proves too rigid for the task, consider splitting up the end-to-end process into process fragments to become more flexible. 
Recreating this end-to-end process from these fragments can be done by structuring them through a case that indicates the major phases in the process. 
As such these fragments become once again linked, but still retain a dynamic and adaptable nature. 
This is the <a href="https://www.youtube.com/watch?v=uSQVtm8O7SA&amp;t=1s&amp;ab_channel=bpmNEXT%3ADefiningtheNextGenerationofProcessInnovation" target="_blank" rel="noopener noreferrer">intentional process</a> as posited by the people from Flowable.</p>

<p>It is easy to have initiatives for intelligent automation derail, but here we can apply the same lessons we learned for process management adoption:</p>
<ol>
  <li>Make everyone, on every level, in the organization aware of the benefits and how it will help them in their jobs, not replace them. It alleviates tedious repetitive work and frees up time for employees to pursue more worthwhile endeavors within their organization.</li>
  <li>Think Big, Start Small. It is okay to have a grandiose goal in mind. But starting with a simple proof of concept to show quick results goes a long way to prepare for more complex processes and garner goodwill from those involved.</li>
  <li>If at all possible, get expert help for those first few initiatives to build up expertise within the organization.</li>
  <li>Get intimately acquainted with the data assets available to your processes, in the organization, and external data. What they are, in which format they exist, and their availability. This understanding will facilitate the analytics involved.</li>
</ol>

<h2 id="robots">Robots</h2>

<p>When it comes to robots, RPA springs to mind. 
But it is not the only game in town. 
Automation can also be handed over to an AI, which can determine things like the shortest path (think of your GPS) and other non-trivial decisions. 
The illustration below showcases the most common attributes of both these types of robots.</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/rpavsai.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Taken from the <a href="https://www.bcg.com/publications/2017/technology-digital-operations-powering-the-service-economy-with-rpa-ai?linkId=39429569" target="_blank" rel="noopener noreferrer">Boston Consulting Group Website</a></p>

<p>Looking at the work automation spectrum, we can easily pinpoint where RPA and AI can lend a hand to the classic way of process automation. 
We can also determine where knowledge workers will have the biggest added value. 
These business experts have accumulated an immeasurable wealth of knowledge and expertise that constantly faces an inevitable expiration date (be it pensions or even turnover). 
Safeguarding this knowledge through proper knowledge management often is a set of processes on its own to which intelligent automation can once again be applied.</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/rpa-ai-balance.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<p>For RPA, the biggest gains will be attained by using the robots as a stepping stone to digital maturity in your process automation. 
They are tools to be used to quickly replace error-prone human tasks and capitalize on the quick gains this provides. 
They can also be utilized to quickly set up proof-of-concept endeavors to prove added value derived from ideation. 
Once these steps in the automated process reach the proper level of maturity, they can then more easily be replaced by technologies that trade in the hyper agility RPA provides for more grip on the governance and maintainability that API solutions offer. 
Camunda specified a three-step approach along those lines in their 2020 White Paper titled <a href="https://camunda.com/blog/2021/01/beyond-rpa-how-to-build-toward-end-to-end-process-automation/" target="_blank" rel="noopener noreferrer">“Beyond RPA: How to Build Toward End-to-End Process Automation”</a>. 
These steps are the following:</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/rpause.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<p>A big part of the added value realized by introducing AI robots into the process automation toolbox is knowing where and when to use them. 
Predictive models can help decisioning in organizations, but there are some points to keep in mind:</p>
<ul>
  <li>At its core, effective decisioning should not only answer the “What is Happening?” question, but also the “Why is it happening?”-question. This understanding of the reasons behind information leads to better opportunity detection and initiatives.</li>
  <li>Risk/Reward considerations should be available with each option of the decisions.</li>
  <li>Even with decisions where there are ambiguous or even unknown factors, or where the risk/reward cannot be determined, there is a need to automate, and this is where deep learning/machine learning models can make the difference.</li>
</ul>

<p>The types of tasks that RPA and AI can alleviate are then:</p>
<ul>
  <li>Tasks that are easy to do when there are few, but become cumbersome in large amounts.</li>
  <li>Tasks that are not easy for humans to perform, such as high-speed or high-complexity algorithms.</li>
  <li>Tasks that require the interpretation and/or parsing of large amounts of knowledge (such as a volume of laws or a medical database).</li>
</ul>

<p>Although the degree of independence with which robots can execute these tasks varies widely from case to case. 
Most of these will still require some human interaction to conclude them. 
But it is clear that robot-assisted work has a great benefit over not using robots to aid you in performing knowledge work.</p>

<p>The components that can assist in tackling these points are the following:</p>
<ul>
  <li>Data Integration Agents: These components integrate disparate data sources into a common data repository environment with a focus on cataloging, constructing ontologies, setting up multi-dimensional discovery, domain model creation, and a self-learning data search interface.</li>
  <li>Analytics Agents: These components perform cognitive analysis of available data, correlating and determining data relationships.</li>
  <li>Visualization Agents: As the name suggests, these components allow for the construction of visualizations and support for derived information gathering such as natural language processing, speech recognition, and customer satisfaction analysis.</li>
</ul>

<h2 id="rules--relationships">Rules &amp; Relationships</h2>

<p>IT is all about the data. 
And with the introduction of machine learning, the need for this data to be structured has dropped significantly. 
Traditional BPM tells us that data/information steers the process. 
It decides which route is taken through its execution. 
But with unstructured data in the mix, this becomes a lot harder. 
As such, interpreting this data correctly has become a science. 
Data science has become a de facto foundation for every digital transformation effort. 
When we speak of intelligent business processes, the role data plays has outgrown the classic summaries and reports delivered to the process manager and has taken on the form of the process able to dynamically digest and process an ever-changing data set. 
This data set needs to combine both the transactional process data and the integration-based business data to leverage results in correct business decisions.</p>

<p>The three data pillars for process data were stipulated in Winkler &amp; Kay’s 2019 article ‘Macro Evolution of BPM Data’, and are the following:</p>
<ol>
  <li>Historical Process Data</li>
  <li>Run-time Patterns</li>
  <li>AI/ML-based Forecasting</li>
</ol>

<h3 id="historical-process-data">Historical Process Data</h3>

<p>The obvious data associated with processes is the statistical representation of process behavior (who did what how many times). 
Combined with the effect of business process results on the ongoing business, it shows a clear route on where to finetune and improve our processes. 
This is the bread and butter of the process analyst. 
An example of what this might entail can be seen below:</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/relevant-data-01.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Business and Process Data analytics example in BPM, Winkler, Kay; 2019</p>

<h3 id="run-time-patterns">Run-time Patterns</h3>

<p>Performance metrics add to the previous category of process data. 
More difficult to determine, these numbers underpin most business cases and justifications for BPM initiatives. 
They can be leveraged to determine the Return-on-Investment (ROI), and help to pinpoint the bottlenecks in known business processes.</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/relevant-data-02.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Task Cycle Time; Winkler, Kay; 2019</p>

<h3 id="aiml-based-forecasting">AI/ML-based Forecasting</h3>

<p>Applying Machine Learning to process data is not undertaken lightly. 
It requires a certain level of maturity in both historical process data and run-time patterns before attempting to extract actionable intelligence this way. 
The payout is worth the while, even with the sometimes overwhelming amount of data and information to sift through. 
Gathering all the information avenues into a dedicated repository gives the option for broader correlational analytics (such as time series and cross-sectional investigations). 
Process Mining will amp up your process optimization game and indicate new avenues to explore for such optimizations.</p>

<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/relevant-data-03.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Stages of Process Analytics; Winkler, Kay</p>

<p>If this still does not give the appropriate support for efficiency and effectiveness, applying some frameworks such as Figure of Merit Matrices (FOMM) to increase effectiveness and Resource Allocation, Leveling and Balancing (RALB) to increase efficiency can assist you to achieve the goals your organization has set out.</p>

<h2 id="putting-it-all-together">Putting it all Together</h2>

<p>When leveraging all the tools of intelligent automation, there are concerns as to which goals contradict each other. 
Just like in corporate strategy, you cannot full-out go for both operational excellence (typically by standardizing to a black Ford Model T) and customer intimacy (with a car that is tailor-made to one unique individual), there are trade-offs and balances to be weighed. 
For automation in general these are:</p>
<ul>
  <li>Digital Innovation Speed: Accelerated development for automation using the latest tools and techniques.</li>
  <li>Digital Competency Best Practices: Going for controlled automation with proven technologies, frameworks, and best practices.</li>
</ul>

<p>And just as with corporate strategy, this balance can shift over time, maybe even with more agility. 
For this, a Center of Excellence (CoE) dedicated to the art of automation is a life boon. 
If you are curious about how to correctly set up such an entity, look at <a href="https://evolute.be/reviews/reimaginemgmt.html" target="_blank" rel="noopener noreferrer">my review of Roger Tregear’s book “Reimagining Management”</a>. 
The 7 Enablers approach in this book will give you a clear path forward on how to achieve this on a corporate level. 
But on a  process level, your considerations are business enablement, continuous review of its performance (for example by applying Lean Six Sigma practices), proper governance, and re-use.</p>

<p>If we map the benefits to the individual tools and best practices we get the following conclusions:</p>
<ul>
  <li>Classic iBPMS combined with RPA will give us the tools to streamline processes, enable straight-through processing, and frees up time from knowledge workers that can be spent on more value-adding and less repetitive activities.</li>
  <li>AI allows for skill-based routing, faster response times to customers in straightforward requests, and support for decisioning (next best step analysis).</li>
  <li>As expected re-use and standardization help with cost reduction while still allowing specialization in those areas that benefit the most from customization and variety in possibilities.</li>
  <li>Cloud adoption will assist in covering security concerns and redundancy needs to ensure business continuity. It also allows for closer matching of IT resources to the consumption of these services, so that financial gains can be achieved in this way (much in the same way as re-use and standardization would).</li>
</ul>

<h2 id="pitfalls-of-intelligent-automation">Pitfalls of Intelligent Automation</h2>

<p>There are also risks associated with any architectural trade-off. 
Here we will list some of the pitfalls the case studies in the book mention. 
These should be detected when present in these types of projects and proper mitigations should be devised.</p>
<ul>
  <li>The obvious one for each of these types of initiatives: Think big, but start small!</li>
  <li>Process Automation should never be an IT story, but should be embraced by business people as well to have it be successful. All parties involved should work towards continuous improvement. This includes upper management. A business sponsor for these initiatives should bridge the gap on this account.</li>
  <li>Connections make up the brunt of the complexity associated with IT initiatives. Make sure your solutions are robust and can deal with connections not always available.</li>
  <li>You should not automate processes without the proper control and measuring tools to follow them up. Working in the dark leaves you blind to problems and opportunities for improvement.</li>
  <li>Don’t try to come up with a better wheel. ‘Search for a Commercial-off-the-Shelf component before you Automate’ should be a mantra in process thinking.</li>
  <li>Don’t try to create complete comprehensive processes from the beginning. You won’t be able to capture all requirements in the first iteration. Build your solution for adaptability to embrace new requirements as they become known.</li>
</ul>

<p>The main realization to make is to determine the maturity of your organization in four distinct areas: data, training, deployment, and management. 
In each of these areas, an increase in maturity will yield additional benefits as shown in the table below:</p>
<p style="text-align: center;"><img src="/img/2023-02-20-intelligent-automation/mlmaturity.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>The book focuses much of its content on the analytics and data sciences part of the intelligent automation ecosystem. 
While this gives the reader insights into how this field plays an important role, it left me with an unsatisfied hunger with regard to all other disciplines that are in play when attempting the initiatives needed to successfully roll out intelligent automation adoption in organizations.</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Peter&quot;, &quot;last_name&quot;=&gt;&quot;De Kinder&quot;, &quot;github&quot;=&gt;&quot;peterdekinder&quot;, &quot;linkedin&quot;=&gt;&quot;peterdekinder&quot;, &quot;permalink&quot;=&gt;&quot;/author/peterdekinder/&quot;, &quot;avatar&quot;=&gt;&quot;peterdekinder.jpg&quot;, &quot;title&quot;=&gt;&quot;Solution Architect&quot;, &quot;email&quot;=&gt;&quot;peter.dekinder@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Peter is a Solution Architect with firm roots in the Java technosphere, but with a wide interest in all things architecture. His areas of specialization include Service Oriented Architectures, Business Process Management and Security.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2020-01-28-Architecture-in-Projects.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-03-24-Charting-non-functionals.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-07-08-Book-Five-Dysfunctions.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-11-25-Quite-The-Story.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-01-04-Designing-REST-services.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-02-17-Out-With-The-Old.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-01-14-what-would-discord-bot-do.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-06-13-connecting-the-pods.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-24-ode-to-join.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-02-20-intelligent-automation.md collection=posts&gt;]}</name><email>peter.dekinder@ordina.be</email></author><category term="Architecture" /><category term="architecture" /><category term="software architecture" /><summary type="html"><![CDATA[Already 4 years ago, Nathaniel Palmer’s keynote at bpmNext introduced me to the concept of Intelligent Automation. This is the extension of the classical Process Management approach using Intelligent Business Process Management Solutions (iBPMS) to automate processes with the influx of new possibilities on a technological level: AI and machine learning to crunch the data, RPA, and the introduction of bots for automating swivel chair processes, and more pronounced use of decision management automation. When the titular book was published by Future Strategies, I picked up my copy and started reading in the hopes of figuring out how to implement this. The book is similar in structure to other volumes of Future Strategies in that it is a collection of articles by luminaries in the field, accompanied by several award-winning case studies.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2023-02-20-intelligent-automation/header.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2023-02-20-intelligent-automation/header.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Accelerating your slow Java Lambda with AWS Lambda SnapStart</title><link href="https://ordina-jworks.github.io/cloud/2023/01/13/aws-lambda-snapstart-spring-cloud-function.html" rel="alternate" type="text/html" title="Accelerating your slow Java Lambda with AWS Lambda SnapStart" /><published>2023-01-13T00:00:00+00:00</published><updated>2023-01-13T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/cloud/2023/01/13/aws-lambda-snapstart-spring-cloud-function</id><content type="html" xml:base="https://ordina-jworks.github.io/cloud/2023/01/13/aws-lambda-snapstart-spring-cloud-function.html"><![CDATA[<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#what-is-snapstart">What is SnapStart?</a>
    <ul>
      <li><a href="#versions">Versions</a></li>
      <li><a href="#pricing">Pricing</a></li>
      <li><a href="#limitations">Limitations</a>
        <ul>
          <li><a href="#uniqueness">Uniqueness</a></li>
          <li><a href="#networking">Networking</a></li>
          <li><a href="#ephemeral-data">Ephemeral data</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#using-snapstart">Using SnapStart</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="introduction">Introduction</h2>
<p>If you use <a href="https://aws.amazon.com/lambda/" target="_blank" rel="noopener noreferrer">AWS Lambda</a> in combination with Java runtimes, you will notice (or probably have already noticed) that one of the main setbacks is the cold start time.
A cold start refers to the process where a Lambda is invoked for the first time and the Lambda has to be initialized.
AWS needs to create a new function instance and spin it up with every <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-ib" target="_blank" rel="noopener noreferrer">initialization</a>.</p>

<p>Depending on your environment and application size, it can take up to 10 seconds to complete the init phase.
Especially when using frameworks such as Spring Boot where features like dependency injection and component scanning can take a lot of time to initialize.
This is a delay that most want to avoid as it significantly slows down your application flow in some situations.
<strong>Do mind</strong> that this is only during the init phase; once the Lambda instance is running, the cold start process is over until the next time your Lambda needs to be instantiated again.</p>

<p style="text-align: center;"><img src="/img/2022-12-23-aws-lambda-snapstart-spring-cloud-function/lambda-execution-lifecycle.png" alt="Lambda execution lifecycle" class="image fit" style="margin:0px auto; max-width:100%" />
<em>Lambda execution environment lifecycle - without SnapStart - <a href="https://www.youtube.com/watch?v=dnFm6MlPnco" target="_blank" rel="noopener noreferrer">Best practices of advanced serverless developers (AWS re:Invent 2021)</a></em></p>

<p>AWS has always recognized the problem and now comes with a solution called <a href="https://docs.aws.amazon.com/lambda/latest/dg/snapstart.html" target="_blank" rel="noopener noreferrer">Lambda SnapStart</a>.</p>

<h2 id="what-is-snapstart">What is SnapStart?</h2>
<p>Introduced at AWS re:Invent 2022, AWS <a href="https://docs.aws.amazon.com/lambda/latest/dg/snapstart.html" target="_blank" rel="noopener noreferrer">Lambda SnapStart</a> is the newest feature to eliminate the cold start problem by initializing the function when you publish a new version of a Lambda.
It takes a snapshot, through <a href="https://firecracker-microvm.github.io/" target="_blank" rel="noopener noreferrer">Firecracker</a> which AWS uses to run Lambda and Fargate, encrypts and caches it so it can be instantly accessed whenever it is required.
When a Lambda is invoked and needs to set up a new instance, it will simply use the cached snapshot, which greatly improves startup times (officially up to 10x).</p>

<h3 id="versions">Versions</h3>
<p>By default, SnapStart is disabled.
You can enable it, but only for published Lambda versions.
This means that it only works for versions that are published on the AWS account and that it is not implemented on the $LATEST tag. If you want to make use of Lambda SnapStart, be sure to do so on a published version.
The snapshot of your Lambda is created upon the version publishing process.</p>

<p style="text-align: center;"><img src="/img/2022-12-23-aws-lambda-snapstart-spring-cloud-function/snapstart-overview.png" alt="SnapStart overview" class="image fit" style="margin:0px auto; max-width:100%" />
<em>SnapStart overview - snapshot gets created during version publishing - <a href="https://www.youtube.com/watch?v=ZbnAithBNYY" target="_blank" rel="noopener noreferrer">AWS Lambda SnapStart (AWS re:Invent 2022)</a></em></p>

<h3 id="pricing">Pricing</h3>
<p>The SnapStart feature comes with AWS Lambda and has no additional pricing.</p>

<h3 id="limitations">Limitations</h3>
<p>While SnapStart is a great feature and can save time in Lambda cold starts, it also comes with its limitations.
SnapStart currently does not support the following features and services:</p>
<ul>
  <li><a href="https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html" target="_blank" rel="noopener noreferrer">provisioned concurrency</a></li>
  <li>arm64 architecture</li>
  <li>the <a href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-extensions-api.html" target="_blank" rel="noopener noreferrer">Lambda Extensions API</a></li>
  <li><a href="https://aws.amazon.com/efs/" target="_blank" rel="noopener noreferrer">EFS</a></li>
  <li><a href="https://aws.amazon.com/xray/" target="_blank" rel="noopener noreferrer">X-Ray</a></li>
  <li>Ephemeral storage up to 512 MB</li>
  <li>Limited to Java 11 runtime</li>
</ul>

<h4 id="uniqueness">Uniqueness</h4>
<p>SnapStart always requires your snapshot to be unique. 
This means that if you have initialization code that generates unique content, it might not always be unique in the snapshot once it is restored in other Lambda invocations.
The goal is to generate this content after the initialization process, so it is not part of the snapshot.
Luckily, AWS has provided a <a href="https://docs.aws.amazon.com/lambda/latest/dg/snapstart-uniqueness.html" target="_blank" rel="noopener noreferrer">documentation page</a> in which they provide best practices on how to tackle that problem.
They even came up with a <a href="https://github.com/aws/aws-lambda-snapstart-java-rules" target="_blank" rel="noopener noreferrer">SpotBugs plugin</a> which finds potential issues in your code that could prevent SnapStart from working correctly.</p>

<h4 id="networking">Networking</h4>
<p>Network connections are not being shared across different environments.
Thus, if network connections (for example, to other AWS services such as an RDS or SQS) are instantiated in the initialization phase, they will not be shared and will most likely fail when the snapshot is being used later again.
Although most popular frameworks have automatic database connection retries, it is worth the time to make sure that it works correctly.</p>

<h4 id="ephemeral-data">Ephemeral data</h4>
<p>Data that is fetched or temporary (for example a password or secret) should be fetched after the initialization phase.
Otherwise, it will save the secret in the snapshot, meaning that authentication failures (and security risks) might occur once the initial secret value has expired or has been changed.</p>

<h2 id="using-snapstart">Using SnapStart</h2>
<p>To investigate the improvement in cold start execution time when using AWS Lambda SnapStart, we wrote a simple Lambda function in Java 11 using <a href="https://spring.io/projects/spring-cloud-function" target="_blank" rel="noopener noreferrer">Spring Cloud Function</a>.
This Lambda function, when invoked, will retrieve some JSON data from a <a href="https://dummyjson.com/" target="_blank" rel="noopener noreferrer">dummy REST API</a> and return it to the user.
The code can be found on <a href="https://github.com/ordina-jworks/aws-lambda-snapstart-spring-boot" target="_blank" rel="noopener noreferrer">Github</a>.</p>

<p>We made use of the <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html" target="_blank" rel="noopener noreferrer">AWS Serverless Application Model (SAM)</a> to build our Lambda function and deploy it to AWS.
Enabling the SnapStart feature can be easily done by adding the following two lines to the <code class="language-plaintext highlighter-rouge">Properties</code> section of the Lambda function resource in the <code class="language-plaintext highlighter-rouge">template.yaml</code> file used by AWS SAM:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SnapStart:
  ApplyOn: PublishedVersions
</code></pre></div></div>

<p>We started by invoking our Lambda function’s unpublished version ($LATEST), in which case SnapStart is not used, and received the following summary from AWS:</p>

<p><img src="/img/2022-12-23-aws-lambda-snapstart-spring-cloud-function/lambda-cold-start.png" alt="Summary lambda without SnapStart" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<p>We can observe an <strong>Init duration</strong> of around 2.7s, i.e. the time that is spent initializing the execution environment for our Lambda function.</p>

<p>Next, we manually published a new version of our Lambda function using the AWS Console.
This can be done by navigating to the <em>Versions</em> tab of our Lamdba function and pressing the <em>Publish new version</em> button.</p>

<p style="text-align: center;"><img src="/img/2022-12-23-aws-lambda-snapstart-spring-cloud-function/lambda-versions.png" alt="Lambda function verions" class="image fit" style="margin:0px auto; max-width:100%" />
<em>Versions tab listing all published versions of a Lambda function.</em></p>

<p>Invoking this newly published version provides us with the following summary:</p>

<p><img src="/img/2022-12-23-aws-lambda-snapstart-spring-cloud-function/lambda-snapstart.png" alt="Summary lambda with SnapStart" class="image fit" style="margin:0px auto; max-width:100%" /></p>

<p>In this case, we can see SnapStart is used.
The initialization of the execution environment, represented by the <strong>Init duration</strong> we saw earlier, now happens when publishing the new version.
Only the restoration of the snapshot, represented by the <strong>Restore duration</strong>, is performed now.</p>

<p>It is quite clear that using Lambda SnapStart is advantageous in most cases.
We managed to decrease the cold start execution time of our Lambda function from almost 5s (<strong>Init duration</strong> + <strong>Duration</strong>) to around 2.6s (<strong>Restore duration</strong> + <strong>Duration</strong>), just by enabling this feature.</p>

<h2 id="conclusion">Conclusion</h2>
<p>SnapStart is a great feature and can save a lot of time in your application flow.
It’s a feature that should have been present already as it comes a bit too late. 
But now that it is here, Java developers should take measures in order to implement this as it can save a lot of time in cold-starting their Java Lambdas.
We would have liked to see it implemented by default when you create a version, but sadly, this is not the case (yet).
It comes only for Java, which is understandable as Java Lambdas face this obstacle the most. 
Still, we certainly won’t be surprised if AWS decides to release this feature for other languages and/or frameworks.</p>

<p>Altogether we can definitely recommend using this new feature for your Java Lambdas.</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Yolan&quot;, &quot;last_name&quot;=&gt;&quot;Vloeberghs&quot;, &quot;linkedin&quot;=&gt;&quot;yolan-vloeberghs-23825aa3&quot;, &quot;github&quot;=&gt;&quot;yolanv&quot;, &quot;permalink&quot;=&gt;&quot;/author/yolan-vloeberghs/&quot;, &quot;avatar&quot;=&gt;&quot;yolan-vloeberghs.jpg&quot;, &quot;title&quot;=&gt;&quot;Java Consultant&quot;, &quot;email&quot;=&gt;&quot;yolan.vloeberghs@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Yolan Vloeberghs is a Java and Cloud engineer with a sharpened focus on all things related to cloud, specifically AWS. He loves to play around with various technologies and frameworks and is very passionated and eager to learn about everything related to cloud-native development.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2019-04-02-Kickstarter-Trajectory-2019-Light.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-07-10-Spring-IO-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-08-05-deploy-spring-boot-kubernetes.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-29-AWS-Dev-Day-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-05-07-jib.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-08-28-kubernetes-clients-comparison.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-12-10-aws-fargate-serverless-deployments.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-11-03-selenium-e2e-testing.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-06-13-aws-rds-iam-authentication-spring-boot.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-01-13-aws-lambda-snapstart-spring-cloud-function.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-05-17-kubecon-2023.md collection=posts&gt;]}</name><email>yolan.vloeberghs@ordina.be</email></author><category term="Cloud" /><category term="aws" /><category term="lambda" /><category term="snapstart" /><category term="cloud" /><category term="spring" /><category term="java" /><summary type="html"><![CDATA[Introduction What is SnapStart? Versions Pricing Limitations Uniqueness Networking Ephemeral data Using SnapStart Conclusion]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2023-01-13-aws-lambda-snapstart-spring-cloud-function/header.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2023-01-13-aws-lambda-snapstart-spring-cloud-function/header.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Keeping up with dependencies like a boss</title><link href="https://ordina-jworks.github.io/cloud/2022/10/27/renovate.html" rel="alternate" type="text/html" title="Keeping up with dependencies like a boss" /><published>2022-10-27T00:00:00+00:00</published><updated>2022-10-27T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/cloud/2022/10/27/renovate</id><content type="html" xml:base="https://ordina-jworks.github.io/cloud/2022/10/27/renovate.html"><![CDATA[<blockquote>
  <p>Anything worth doing twice is worth automation.</p>
</blockquote>

<ul>
  <li><a href="#whats-the-problem">What’s the problem?</a></li>
  <li><a href="#what-is-mend-renovate">What is Mend Renovate?</a></li>
  <li><a href="#behind-the-curtains">Behind the curtains</a></li>
  <li><a href="#how-to-setup">How to setup</a></li>
  <li><a href="#tips-and-tricks">Tips and tricks</a></li>
  <li><a href="#why-should-i-use-it">Why should I use it?</a></li>
  <li><a href="#links">Links</a></li>
</ul>

<h2 id="whats-the-problem">What’s the problem?</h2>

<h3 id="lack-of-features">Lack of features</h3>

<p>Let’s imagine you need to implement support for a new feature.
Let’s imagine that that feature is super easy to implement due to almost native support for the functionality in a library you’re already using. 
That sounds like a great day, right? 
You add the code to glue together the API and the library, perform some tests and call it a day. 
There is just one problem, you didn’t check which version of the dependency you were using and the feature you need is only supported in versions 8.x.x and beyond. 
You check your <code class="language-plaintext highlighter-rouge">pom.xml</code>, only to figure out that you’re on version <code class="language-plaintext highlighter-rouge">6.8.21</code>.
Now you have two options, refactor 25% of your codebase to be able to use the new library or 5x your effort for implementing the feature without the support of the library.
That doesn’t sound like a great day at the (home-)office, now does it?</p>

<p>Wouldn’t be great to have been on version <code class="language-plaintext highlighter-rouge">8.1.2</code> already?</p>

<h3 id="dependent-systems">Dependent systems</h3>

<p>Let’s imagine another scenario.
You’re using a library to connect to an Elasticsearch cluster that’s provided by another team. 
Your application is running nicely in production and you’re steadily adding features to the codebase.
The end of the year approaches and with that, the pressure to deliver the final set of promised features increases.
All of a sudden, your application starts throwing all kinds of errors in your development environment. 
After some stressful debugging, you figure out that the Elasticsearch cluster has been upgraded to the latest version by the other team. 
Furiously, you open up your mailbox and look for an email about the upgrade. 
Of course, you find the email dating back four weeks where the team announced that they will start upgrading this week for development and do production in two weeks.</p>

<p>Since it’s a shared system, you can’t fault the other team, nor can you halt their upgrade path. 
So the only way forward is to upgrade the library. 
You open up your <code class="language-plaintext highlighter-rouge">pom.xml</code> file only to discover that you’re already 2 major versions behind. 
Upgrading will take ages since your code depends on previously deprecated and by now removed API support.</p>

<p>That sounds like a lot of overtime, stress and/or missed deadlines for the end of the year, doesn’t it…</p>

<h3 id="security-vulnerability">Security Vulnerability</h3>

<p>Now we get to a scenario that maybe 50% of the Java community experienced at the end of 2021.
A severe security vulnerability was discovered in a very popular logging library: Log4J. 
Normally, vulnerabilities aren’t this severe and there aren’t part of the nine o’clock news.
Now imagine that you are using a vulnerable software component and you aren’t informed by the news that you need to urgently update, how would you know about the vulnerability? 
Maybe you have some scanning software that checks for know CVEs?
Maybe you have really good developers that are subscribed to the mailing lists of all dependencies they’re using?
Or more likely than not, you just don’t know you’re vulnerable. 
OWASP identified <code class="language-plaintext highlighter-rouge">Vulnerable and outdated components</code> as number six on their <code class="language-plaintext highlighter-rouge">Top 10 Web Application Security Risks</code> of 2021.</p>

<p>Wouldn’t it have been nice to have a PR on every repository that had the Log4J dependency with the new version updated? 
So that you only had to merge that PR to mitigate the vulnerability?</p>

<h2 id="what-is-mend-renovate">What is Mend Renovate?</h2>

<p><a href="https://www.mend.io/free-developer-tools/renovate/" target="_blank" rel="noopener noreferrer">Mend Renovate</a> (formerly known as WhiteSource Renovate) is a tool that detects dependencies in your code and informs you about new versions of your dependencies.
It’s a free (at the time of writing) tool that can be used as a GitHub App or as a self-hosted tool. 
Renovate scans a repository and detects the used dependencies, relying on dependency managers.
As of time of writing, Renovate supports about <a href="https://docs.renovatebot.com/modules/manager/" target="_blank" rel="noopener noreferrer">80 different dependency management</a> systems out of the box.
Next, it can integrate with your code repositories (e.g. Bitbucket, Github, Gitlab, …) and automatically update the dependency in your code. 
It can create pull requests (PR) for every update it detects and even adds changelog (if available) information to the PR. 
This is especially helpful if there are (manual) changes required to use the new version of the dependency.
So Renovate can <code class="language-plaintext highlighter-rouge">detect</code> your dependencies, <code class="language-plaintext highlighter-rouge">inform</code> you about the updates and even tell you <code class="language-plaintext highlighter-rouge">how</code> to update.</p>

<h2 id="behind-the-curtains">Behind the curtains</h2>

<p>Now, how does this magic work?</p>

<p>Renovate starts by scanning your source code for dependencies.
It does this by looking for dependency files in your repository, let’s take the file structure below as an example.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>repo/ 
├─ src/ 
├─ Dockerfile 
├─ pom.xml
</code></pre></div></div>

<p>Renovate will detect the Dockerfile and the Maven dependency file (<code class="language-plaintext highlighter-rouge">pom.xml</code>).
It will pass these files to the dependency managers internally and detect which dependencies are being used.
Let’s imagine that the Dockerfile has the following <code class="language-plaintext highlighter-rouge">FROM</code> line at the top: <code class="language-plaintext highlighter-rouge">FROM amazoncorretto:18.0.0</code>
The dependency manager for docker will detect that this is the repository <code class="language-plaintext highlighter-rouge">amazoncorretto</code> with tag <code class="language-plaintext highlighter-rouge">18.0.0</code> on Docker Hub.
Next, it will look in the <code class="language-plaintext highlighter-rouge">pom.xml</code>.</p>

<p>Excerpt of the pom.xml:</p>
<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.apache.logging.log4j<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>log4j-core<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>2.12.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>
<p><strong>Note: Never use this dependency! This is a vulnerable version of log4j-core.</strong></p>

<p>Renovate will detect the following Maven dependency: <code class="language-plaintext highlighter-rouge">org.apache.logging.log4j:log4j-core:2.12.2</code></p>

<p>Next, Renovate will check for new versions of those dependencies. 
By default, Renovate will use the central Apache Maven Repository to check for newer versions of Maven dependencies. 
For Docker images, Docker Hub is used by default.
Like almost everything in Renovate, you can configure it to use different data sources, like your own Nexus, Artifactory or AWS Elastic Container Registry for example.
This way you can limit what sources are considered and you can also use Renovate to update internal dependencies instead of just public ones.</p>

<p>Now let’s imagine that the most recent version of the <code class="language-plaintext highlighter-rouge">amazoncorretto</code> image is <code class="language-plaintext highlighter-rouge">18.0.2</code> (This is <code class="language-plaintext highlighter-rouge">latest</code> at the time of writing).
Renovate will create a branch from your main branch, update the <code class="language-plaintext highlighter-rouge">FROM</code> entry in your Dockerfile and push the changes into your repository as a new branch. 
Now your regular CI/CD process can be followed to build, test, merge and deploy your component with the updated dependency.</p>

<p>The same scenario, with a second branch, will be performed to update the log4j dependency.</p>

<p>As an additional bonus, if the dependency exposes it, Renovate will add the changelogs in the pull/merge request it creates in your repository.
This makes it visible if any breaking changes were introduced and allows you to easily check, together with your tests, if you need to make changes to your code to update the dependency.</p>

<p>Example of changelogs embedded in PR.</p>
<p style="text-align: center;"><img src="/img/20221009-renovate/pr-changelog.png" alt="PR with changelogs" class="image center" style="margin:0px auto; max-width:100%" /></p>

<h2 id="how-to-setup">How to setup</h2>

<p>How to use Renovate depends a bit on where your code lives.</p>

<h3 id="renovate-github-app">Renovate GitHub App</h3>

<p>If you’re using GitHub, the setup is as easy as enabling the <a href="https://github.com/apps/renovate" target="_blank" rel="noopener noreferrer">GitHub Renovate app</a> for your repository. 
Next, Renovate will create an onboarding pull request where it will suggest a default Renovate configuration, show a preview of what dependencies it detected and an example of what updates it has found. 
The only thing left is to merge the pull request and renovate will automatically start scanning your repository and start creating branches and pull requests with dependency updates.</p>

<h3 id="self-hosted-renovate">Self-hosted Renovate</h3>

<p>The second option is to host Renovate yourself.
This option also comes with a lot more configuration capabilities, especially w.r.t. private data sources. 
You can run Renovate <a href="https://docs.renovatebot.com/examples/self-hosting/#gitlab-cicd-pipeline" target="_blank" rel="noopener noreferrer">as (part of) a pipeline</a>, as a <a href="https://docs.renovatebot.com/examples/self-hosting/#docker" target="_blank" rel="noopener noreferrer">Docker container</a> or even as a <a href="https://docs.renovatebot.com/examples/self-hosting/#kubernetes" target="_blank" rel="noopener noreferrer">CronJob on Kubernetes</a>.
Since you only need NodeJS/NPM to be available, you can run it almost anywhere you want. 
You can find an example of how to run Renovate as a Cronjob on a Kubernetes cluster in <a href="https://github.com/pietervincken/renovate-tekton-argo-talk/tree/main/k8s/renovate" target="_blank" rel="noopener noreferrer">this repository</a>.</p>

<p>With the self-hosted deployment method, you need to either explicitly tell Renovate which repositories it needs to consider or configure it to auto-detect repositories based on the access of its user or the integration with your code repositories.
For Bitbucket Server you can for example configure Renovate to automatically discover all repositories in a specific project.
This prevents you from having to make changes to the Renovate configuration every time a new repository gets added.</p>

<p>In this scenario, you’ll have to provide Renovate an identity to interact with the code repositories as well, as it needs to be able to create branches and push code changes.</p>

<h2 id="tips-and-tricks">Tips and tricks</h2>

<p>Aka things we discovered and/or went wrong while we started using Renovate.</p>

<h3 id="limit-concurrent-branches--prs">Limit concurrent branches / PRs</h3>

<p>An important tip, especially if your repository contains quite some outdated components, is to limit the number of concurrent branches and pull requests that Renovate is allowed to create. 
By default, Renovate is not limited to a specific number which might result in literally 10s if not over 100 pull requests being created. 
To prevent you and/or your developers from becoming overwhelmed by this, <a href="https://docs.renovatebot.com/configuration-options/#prconcurrentlimit" target="_blank" rel="noopener noreferrer">limiting the concurrent pull requests</a> is a must!</p>

<h3 id="setup-auto-merging">Setup auto-merging</h3>

<p>Auto-merging is a very powerful feature in Renovate, especially in combination with very good automated tests and continuous integration practices. 
<strong>Don’t</strong> enable this when starting with Renovate. 
Over time, you’ll be able to identify repositories and data sources for which updates are becoming as easy as just accepting the PRs. 
For these combinations of repositories and data sources, you can enable auto-merging in Renovate. 
This means that Renovate will perform the update to the code repository and if the result of the pipeline for that change is green, it will attempt to merge that PR.
If you have a well-automated CI/CD process, this can allow Renovate to automatically update your dependencies and make sure that your software automatically has the latest dependencies.</p>

<h3 id="use-it-in-deployment-repositories">Use it in deployment repositories</h3>

<p>The term dependency is interpreted quite broadly in Renovate. 
Not only classical libraries and Docker base images can be detected. (aka build phase dependencies)
It can also detect dependencies in your deployment setups. 
This means that it can detect updates in <a href="https://docs.renovatebot.com/modules/manager/ansible/" target="_blank" rel="noopener noreferrer">Ansible playbooks</a>, update <a href="https://docs.renovatebot.com/modules/manager/helmv3/https://docs.renovatebot.com/modules/manager/helmv3/" target="_blank" rel="noopener noreferrer">Helm Chart</a> references, update <a href="https://docs.renovatebot.com/modules/manager/kubernetes/" target="_blank" rel="noopener noreferrer">Kubernetes manifests</a> (including the API versions as shown below!) and even <a href="https://docs.renovatebot.com/modules/manager/kustomize/" target="_blank" rel="noopener noreferrer">Kustomize</a> and <a href="https://docs.renovatebot.com/modules/manager/terraform/" target="_blank" rel="noopener noreferrer">Terraform</a> setups.</p>

<p>Enabling automated dependency management for those deployment repositories can greatly reduce the amount of effort that is required to update a newer external dependency. 
It also helps to make sure that an update is rolled out consistently across many different environments. 
Especially in a larger corporate context, it can be hard to determine what the latest version of a specific service is and on which environments it’s running or not. 
By enabling Renovate to detect the dependencies, it can easily inform the different teams/users of newer versions.</p>

<p>Example of automated Kubernetes API updates.</p>
<p style="text-align: center;"><img src="/img/20221009-renovate/k8s-api-update.jpg" alt="Kubernetes API updates" class="image center" style="margin:0px auto; max-width:100%" /></p>

<h3 id="start-slow">Start slow!</h3>

<p>The last tip might sound a bit contradictory, but starting small with Renovate is key. 
You want to build confidence in the data sources you’re using and prevent your teams from being overwhelmed by Renovate PRs. 
A good way to start with Renovate is to enable it on just one or maybe a handful of low-impact repositories. 
This way, you can see what effect it has on your workflow and how teams react to having these PRs pop up in their change feed.</p>

<h2 id="why-should-i-use-it">Why should I use it?</h2>

<p>At the start of this blog post, we’ve discussed why updating dependencies is important.
As discussed, bulk updating dependencies is an option, but it might be time-consuming and therefore might be bumped to the bottom of the priority list.
Not to mention that you might miss important security updates if you need to “look” for the changes manually. 
Automating the update process and allowing a tool to automatically discover the updates, makes the update process a lot simpler and faster. 
If you already have a good CI/CD process that allows you to build, test, merge and deploy small changes easily, Renovate will save you tons of time and prevent you from running unsafe, outdated software.</p>

<p>And as one of my favorite sayings goes: <strong>anything worth doing twice is worth automating</strong></p>

<h3 id="links">Links</h3>

<ul>
  <li><a href="https://www.mend.io/free-developer-tools/renovate/" target="_blank" rel="noopener noreferrer">Mend Renovate website</a></li>
  <li><a href="https://github.com/renovatebot/renovate" target="_blank" rel="noopener noreferrer">Renovate Github Repository</a></li>
  <li><a href="https://docs.renovatebot.com/" target="_blank" rel="noopener noreferrer">Renovate docs</a></li>
  <li><a href="https://youtu.be/fAEbRmD4-G0" target="_blank" rel="noopener noreferrer">JOIN 2022 Talk YouTube Link</a></li>
  <li><a href="https://github.com/pietervincken/renovate-tekton-argo-talk/tree/main/k8s/renovate" target="_blank" rel="noopener noreferrer">Sample Renovate Setup</a></li>
</ul>

<p>This blog post is a companion to a talk at the JOIN 2022 conference.</p>

<p>Feel free to reach out to <a href="https://www.linkedin.com/in/pieter-vincken-a94b5153/" target="_blank" rel="noopener noreferrer">me</a> if you want to look into this solution.</p>

<p>Special thanks to the Unicorn team for helping with the blog post and automating the dependency updates!</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Pieter&quot;, &quot;last_name&quot;=&gt;&quot;Vincken&quot;, &quot;linkedin&quot;=&gt;&quot;pieter-vincken-a94b5153&quot;, &quot;twitter&quot;=&gt;&quot;PieterVincken&quot;, &quot;github&quot;=&gt;&quot;pietervincken&quot;, &quot;permalink&quot;=&gt;&quot;/author/pieter_vincken/&quot;, &quot;avatar&quot;=&gt;&quot;pieter-vincken.jpeg&quot;, &quot;title&quot;=&gt;&quot;Cloud Automation Engineer&quot;, &quot;email&quot;=&gt;&quot;pieter.vincken@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Pieter Vincken is a Cloud Automation Engineer with a strong interest in anything related to Cloud Native. He likes to optimize development workflows, from Ideation until code running in production, by enabling CI/CD to be fully automated. Any solutions he creates, will have started as an architectural drawing.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2019-05-03-istio-service-mesh-s2s.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-09-18-kustomize.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-18-devoxx-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-06-02-terraform.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-08-28-kubernetes-clients-comparison.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-10-15-5-reasons-not-to-go-to-the-cloud.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-02-14-postgres-ai.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-06-10-kubecon.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-27-renovate.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-05-17-kubecon-2023.md collection=posts&gt;]}</name><email>pieter.vincken@ordina.be</email></author><category term="Cloud" /><category term="cloud" /><category term="automation" /><category term="cicd" /><summary type="html"><![CDATA[Anything worth doing twice is worth automation.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/20221009-renovate/logo.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/20221009-renovate/logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Ode to JOIN</title><link href="https://ordina-jworks.github.io/architecture/2022/10/24/ode-to-join.html" rel="alternate" type="text/html" title="Ode to JOIN" /><published>2022-10-24T00:00:00+00:00</published><updated>2022-10-24T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/architecture/2022/10/24/ode-to-join</id><content type="html" xml:base="https://ordina-jworks.github.io/architecture/2022/10/24/ode-to-join.html"><![CDATA[<p>We had JOIN, we had fun, we had seasons in the sun. 
It has already been a month since the 9th edition of the JOIN conference was concluded. 
And even though it had been ten years since the first edition, the skipped year due to the pandemic will cause us to have an additional anniversary edition next year. 
The aluminum edition will be a sight to see, and it would be a shame to miss it.</p>

<p>As for this edition, the stakes were high with a new team taking over the reins of those who had come before them. 
As a member of this new team, I had the pleasure to rise to the occasion and make sure the legacy stayed untarnished. 
The new team did not disappoint, and even though there were minor hiccups during the day, in the end, the conclusion was clear. 
A job well done, and a crowd that had gotten a day’s worth of interesting talks topped off with a barbecue blessed with early autumn sun.</p>

<p style="text-align: center;"><img src="/img/2022-10-24-ode-to-join/JOIN-01.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Pieter Van den Wyngaert Opening the Conference in Style</p>

<p style="text-align: center;"><img src="/img/2022-10-24-ode-to-join/JOIN-02.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Getting the inside scoop from our friends at AWS</p>

<p style="text-align: center;"><img src="/img/2022-10-24-ode-to-join/JOIN-03.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Getting to Know your Fellow Conference Goers</p>

<p style="text-align: center;"><img src="/img/2022-10-24-ode-to-join/JOIN-04.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Getting in Touch with the Serverless World (courtesy of November Five)</p>

<p style="text-align: center;"><img src="/img/2022-10-24-ode-to-join/JOIN-05.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Ending the Conference by Queueing up for the Barbecue Diner</p>

<p>Not only did we have a new team, but the founding member of the conference, the jWorks unit or Ordina was joined by their colleagues from the BOLD unit to make it an even more impressive package deal. 
The talks reflected this, not only in a healthy mix of speakers but also in a healthy mix of topics ranging from the concerns about patching 3rd party software to the accessibility concerns of digital products for disabled people. 
We had people from AWS talking about the various ways to modernize applications, and we had people from Flowable showing process automation at its finest. 
On the subject of Flutter, experts brought various insights into the world of mobile app design, and even the mysteries of the design system were laid bare for all to understand.</p>

<p>Even though the topics were varied, the main theme was clear: Software development for the current times, leveraged by the possibilities that are present in the Cloud and the options we have for multi-channel approaches toward the customer. 
Thinking back to the Nexus of Force that Gartner used to taut: Social, Mobile, Analytics, and Cloud, the talks covered three of these four topics. 
Not a bad score for a conference that only lasts a single day.</p>

<p style="text-align: center;"><img src="/img/2022-10-24-ode-to-join/SMAC.png" alt="Workspace" class="image fit" style="margin:0px auto; max-width:100%" />
Taken from the <a href="https://blogs.gartner.com/mark-mcdonald/2022/08/15/relevance-is-customer-and-situationally-specific/smac/" target="_blank" rel="noopener noreferrer">Gartner Blogs Website</a></p>

<p>But shying away from the content for a moment, the process of getting such a conference to happen isn’t as trivial as it might seem. 
Where the preparations range from arranging a venue and finding a date that doesn’t clash too hard with all other conferences in the IT ecosystem, contacting and convincing interesting speakers to grace us with their presence, and setting up a marketing effort to get the word out there, the fun at this point has only begun. 
Facilities need to be arranged, such as making sure the proper recording material can be used to capture these talks for posterity. 
Catering and goodie bags need to be organized to give the attendees the best possible experience. 
You need to make sure that the people you invited to talk have the necessary arrangements to spend the night if needed and get transported for those who require transporting. 
A multitude of things can still get askew during the actual day, and firefighting mode is sometimes required at a moment’s notice.</p>

<p>All of this logistical work does not take away from the fact that we are proud of the ninth IT symphony we have put before our audience with the help of all of those willing to strip up their sleeves and help us out, not in the least the speakers and the technical staff of Elewijt Center that went well beyond the call of duty. 
And even though Beethoven’s magnum opus carried the same edition number, it is our wish that in contract with the maestro, we shall finish our tenth edition next year, and hope to see you all back again.</p>

<p>One closing Remark: The talks will be available on the <a href="https://www.youtube.com/c/OrdinaBelgiumJWorks" target="_blank" rel="noopener noreferrer">JOIN YouTube channel</a> as soon as they have left the capable hands of the post-production team.</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Peter&quot;, &quot;last_name&quot;=&gt;&quot;De Kinder&quot;, &quot;github&quot;=&gt;&quot;peterdekinder&quot;, &quot;linkedin&quot;=&gt;&quot;peterdekinder&quot;, &quot;permalink&quot;=&gt;&quot;/author/peterdekinder/&quot;, &quot;avatar&quot;=&gt;&quot;peterdekinder.jpg&quot;, &quot;title&quot;=&gt;&quot;Solution Architect&quot;, &quot;email&quot;=&gt;&quot;peter.dekinder@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Peter is a Solution Architect with firm roots in the Java technosphere, but with a wide interest in all things architecture. His areas of specialization include Service Oriented Architectures, Business Process Management and Security.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2020-01-28-Architecture-in-Projects.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-03-24-Charting-non-functionals.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-07-08-Book-Five-Dysfunctions.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-11-25-Quite-The-Story.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-01-04-Designing-REST-services.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2021-02-17-Out-With-The-Old.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-01-14-what-would-discord-bot-do.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-06-13-connecting-the-pods.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-24-ode-to-join.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-02-20-intelligent-automation.md collection=posts&gt;]}</name><email>peter.dekinder@ordina.be</email></author><category term="Architecture" /><category term="architecture" /><category term="software architecture" /><category term="Cloud" /><category term="technical leadership" /><summary type="html"><![CDATA[We had JOIN, we had fun, we had seasons in the sun. It has already been a month since the 9th edition of the JOIN conference was concluded. And even though it had been ten years since the first edition, the skipped year due to the pandemic will cause us to have an additional anniversary edition next year. The aluminum edition will be a sight to see, and it would be a shame to miss it.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2022-10-24-ode-to-join/header.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2022-10-24-ode-to-join/header.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Waterfall vs Agile</title><link href="https://ordina-jworks.github.io/agile/2022/10/19/waterfall-vs-agile.html" rel="alternate" type="text/html" title="Waterfall vs Agile" /><published>2022-10-19T00:00:00+00:00</published><updated>2022-10-19T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/agile/2022/10/19/waterfall-vs-agile</id><content type="html" xml:base="https://ordina-jworks.github.io/agile/2022/10/19/waterfall-vs-agile.html"><![CDATA[<blockquote>
  <p>Waterfall or agile for a new project? Benefits or disadvantages?</p>
</blockquote>

<h1 id="table-of-contents">Table of contents</h1>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#software-development-life-cycle">Software Development Life Cycle</a>
    <ul>
      <li><a href="#waterfall">Waterfall</a></li>
      <li><a href="#agile">Agile</a></li>
      <li><a href="#scrumfallwaterscrumagilefallwatergile">Scrumfall/Waterscrum/Agilefall/Watergile</a></li>
    </ul>
  </li>
</ul>

<h1 id="introduction">Introduction</h1>
<p>After my graduation until now, about 10 years, I have worked in many different teams and project, for various clients in various sectors.
During those years, many different styles of project management were used but they always came down to</p>
<ul>
  <li>the more traditional type of project management, also known as waterfall</li>
  <li>a more modern type known as agile</li>
  <li>something in between those 2</li>
</ul>

<p>It is widely known that agile is a big buzzword in more recent years, but what is it exactly?
What is the difference between agile and waterfall?
Which one can be used in which situation?
What are the benefits and disadvantages?</p>

<h1 id="software-development-life-cycle">Software Development Life Cycle</h1>
<p>It is important to know the purpose of a software development life cycle (SDLC). 
The usual explanation for this cycle is</p>
<blockquote>
  <p>A process that produces software with the highest quality and lowest cost in the shortest time possible. 
It typically provides a well-structured flow of phases that help an organization to quickly produce high-quality software 
which is well-tested and ready for production use.</p>
</blockquote>

<p>A mouthful for saying that it provides guidance for delivering software as efficiently as possible, with high quality.</p>

<p>In a SDLC there is a focus on the following 6 phases:</p>
<ul>
  <li>Planning</li>
  <li>Analysis</li>
  <li>Design</li>
  <li>Implementation</li>
  <li>Testing &amp; Integration</li>
  <li>Maintenance</li>
</ul>

<p><img alt="SDLC order" src="/img/2022-10-19-waterfall-vs-agile/sdlc_order.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>There are multiple models of SDLC’s, but the most known are the <em>waterfall</em> and <em>agile</em> model.</p>

<h2 id="waterfall">Waterfall</h2>
<p>The waterfall model is the most traditional type of a SDLC. It has been around since 1970.
It divides the effort into a number of steps and defines that only one step can be active at the same time.
While it usually follows the 6 phases as described above, there’s no limit on it.</p>

<p>From where does it get its name?</p>

<p><img alt="Waterfall order" src="/img/2022-10-19-waterfall-vs-agile/waterfall_order.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>As you can see, it looks like a waterfall. Each step can only start after the previous one is done and thus it cascades down like a waterfall.</p>

<p>Now, when is a step done? Only when the specified artifacts that were defined at the beginning of the step are delivered and accepted.
For the implementation step, this can be a collection of software artifacts that satisfy the design.
For the testing step, it can be a test plan that demonstrates that all the requirements and design are working as intended.</p>

<p>A common mistake is that people think that you can not go back to a previous step. 
It is allowed, but it requires that you stop all work on the current step until the errors in the previous step have been resolved.</p>

<h3 id="pros">Pro’s</h3>
<ul>
  <li>It has detailed documentation and metrics</li>
  <li>The requirements are agreed upon and signed off</li>
  <li>There are less defects as there is rigorous planning and testing</li>
  <li>Defined start and end point which allows for easy measuring</li>
</ul>

<h3 id="cons">Con’s</h3>
<ul>
  <li>It starts slow as the requirements need to be defined in detail</li>
  <li>Changing those requirements takes a lot of effort</li>
  <li>The software is not visible until most of the development work is finished</li>
  <li>Less focus on the client because the requirements are the most important item</li>
</ul>

<h3 id="examples">Examples</h3>
<p>When do we use the waterfall model today?</p>
<ul>
  <li>When requirements can be reliably, quickly and thoroughly defined up front</li>
  <li>For very large teams where common understanding must be put in writing to avoid confusion and miscommunication</li>
  <li>When there is a defined budget and schedule given by the customer</li>
  <li>When there is not much involvement from the customer</li>
</ul>

<p>Building a bridge across a river is a good example of a project that is best done with a waterfall model.
That is a project where a clear schedule is needed and where the requirements need to be defined as soon as possible.
Saying “We will start with the first part of the bridge, evaluate that part and then decide if and how to continue with the remaining parts” is not a possibility here.</p>

<h2 id="agile">Agile</h2>
<p>The agile model has been created in direct response to the waterfall model.
It puts the focus on adaptive, simultaneous workflows which is the opposite from the linear flow of the waterfall model.</p>

<p>Instead of beginning with a complete knowledge of the requirements, the team develops a product in small cycles where small parts are build in a evolutionary way.
Each cycle contains the same steps as defined in the SDLC, but they can all be done at the same time, depending on the experience and skills of the team.
Contrary to the waterfall model, the customer can quickly see and evaluate how the project is advancing at the end of each cycle.
Needed changes to the requirements, based on this evaluation, can be done faster and implemented more easily.
This constant feedback from the client allows the team to adjust to the challenges as they arise and not when it is too late.</p>

<p><img alt="Agile order" src="/img/2022-10-19-waterfall-vs-agile/agile_order.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>The main idea behind the agile model is delivering business value early in the process to lower the risk associated with the development.</p>

<p>The most known implementations of the agile model are Scrum and Kanban, but they all share the same characteristics.</p>

<ul>
  <li>Simultaneous, incremental work</li>
  <li>Adaptability</li>
  <li>Faster and multiple deliverables</li>
</ul>

<h3 id="process">Process</h3>
<p>During agile development, the process usually looks like this:</p>
<ol>
  <li>Define a few initial requirements</li>
  <li>Design</li>
  <li>Develop</li>
  <li>Test</li>
  <li>Deploy</li>
  <li>Evaluate the result of the iteration</li>
  <li>Collect feedback from the various stakeholders</li>
  <li>Start the cycle again with new requirements and the feedback</li>
</ol>

<p><img alt="Agile cycle" src="/img/2022-10-19-waterfall-vs-agile/agile_cycle.jpg" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<h3 id="pros-1">Pro’s</h3>
<ul>
  <li>More project visibility at the end of each cycle</li>
  <li>It is a collaborative and practical approach for executing complex software development projects</li>
  <li>The client and stakeholders have frequent and early opportunities to evaluate the product</li>
  <li>Constant communication between team members so issues can be resolved proactively</li>
</ul>

<h3 id="cons-1">Con’s</h3>
<ul>
  <li>There is a risk for scope creep as agile projects generally have no set end date and thus additional features may be requested</li>
  <li>A multi-skilled resource pool is needed to deliver the project as all knowledge needs to be in the team</li>
  <li>Less detailed documentation as it is considered less important</li>
  <li>Fragmented output can be a problem as multiple teams may work on different components that then need to be put together</li>
</ul>

<h3 id="examples-1">Examples</h3>
<p>When do we use the agile model today?</p>
<ul>
  <li>If there are little to no requirements at the start of the project</li>
  <li>If your organization does not have strict processes to follow and the existing processes are lenient</li>
  <li>If the client or product owner can be highly available to follow the process</li>
  <li>When you’re trying to create something innovative that does not exist yet and needs to go to market quickly</li>
  <li>When the timeline is short and flexible</li>
  <li>When the budget has some wiggle room so that features can be prioritized</li>
</ul>

<p>Agile wins when the requirements are unclear from the beginning or still need to be discovered during the initial development.
More features will be produced in a shorter time frame and the team can be more flexible throughout the process.</p>

<p>A good example would be the development of a social media app. While the initial requirements are clear, further development depends heavily on the demands of the user.
So a start can be made with some basic features that can go quickly to market. Other features will then be implemented after the feedback of the business and most importantly the reactions of the users.</p>

<h2 id="scrumfallwaterscrumagilefallwatergile">Scrumfall/Waterscrum/Agilefall/Watergile</h2>
<p>This model might be known under even more names than the ones above. But it’s basically a software delivery lifecycle that tries to combine the best of both worlds in waterfall and agile.
It usually starts with an up-front design phase and ends with a legacy deployment mechanism, with agile development in between.</p>

<p><img alt="Scrumfall diagram" src="/img/2022-10-19-waterfall-vs-agile/scrumfall_diagram.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>But the name doesn’t matter. Everyone that knows a bit about agile knows that it’s a bad idea to do the entire design up-front and only then start developing. While that might work in a full waterfall model, it doesn’t in agile. 
Waterfall and agile are 2 fundamental different models with conflicts in interest as explained in the previous chapters.</p>

<h3 id="why">Why?</h3>
<p>So even though it’s not the best idea to mix these models, how does it happen that organizations use them?
The results may not be ideal, but it might be enough for some organizations. The agile model mentions all the time that there is not one solution that fits everyone. Every organization must find an approach that is effective for them and which enables them to deliver value.</p>

<p>Who doesn’t know an organization that follows Scrum to the letter, only to find out that it’s not the best approach for them?</p>

<p>Agile is for a large part about discovering new ways of working. As a result, the scrumfall model can be a temporary step towards a full agile transformation.
Now why would organizations keep using this hybrid form?</p>
<ul>
  <li>The IT department is agile and uses Scrum, but the other business departments have never been convinced. And so the organization is divided.</li>
  <li>The organization is stuck with an incomplete transformation and doesn’t know how to continue</li>
  <li>Or they’re in the middle of such a transformation and will finish it shortly</li>
  <li>The organization’s structure is made in such a way that deployment and operations cannot be done by the development teams</li>
</ul>

<h3 id="impact">Impact</h3>
<p>Now, how can this hybrid model impact your organization?
Let’s look at the following image:</p>

<p><img alt="Scrumfall time" src="/img/2022-10-19-waterfall-vs-agile/scrumfall_time.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>The first phase starts with the design as in every model. However, it’s waterfall design, so it takes a while to get everything designed in detail.
This means that during this phase, the development team has nothing to do. They’re just idle.
Once that phase is done and the developers can finally start working, they accelerate and can start delivering. But since the deployment process is still traditional waterfall, it takes a while to get it done. Which means that the feedback loop is going to be a lot slower than in modern agile models.</p>

<p>Slow feedback loops and long release cycles have a high negative impact on the value of the project as everything takes longer and results of various experimentations are harder to see.</p>

<h3 id="problems">Problems</h3>
<p>What are the major problems when you use this model?</p>
<ul>
  <li>Risk and waste: when using agile models, you get feedback by interacting with the business and the end-users. When designing up-front, you can’t anticipate changes in the demands. So when you’re not using a tight feedback loop, you might be creating the wrong thing. Which results in waste when you need to restart.</li>
  <li>Delayed feedback: since the development team is not doing the releases, it will take more time. Time that could be used to find out how the market responds to the new features.</li>
  <li>Long-term damage: the waste that is created has construction and maintenance costs, not to mention decrease in the team’s motivation. All these things have a long-term impact on the organization.</li>
</ul>

<h3 id="way-out">Way out?</h3>
<p>The goal of any organization is to meet the goals of the corporate vision and mission. These goals should be achieved with the greatest efficiency and effect.
If that is done with waterfall or agile is less important. Even scrumfall might work for some organization, be it less effective than a “pure” model.</p>

<p>As with any model, experimentation must be done and improvements must be made. As in agile, this depends from organization to organization how it can be done. There is no one answer that fits for everyone.µ
The most important to keep in mind is that every organization needs to shift its approach to one that decreases waste while increasing quality and predictability.</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Wouter&quot;, &quot;last_name&quot;=&gt;&quot;Nivelle&quot;, &quot;permalink&quot;=&gt;&quot;/author/wouter-nivelle/&quot;, &quot;avatar&quot;=&gt;&quot;wouter-nivelle.jpg&quot;, &quot;title&quot;=&gt;&quot;Project Manager&quot;, &quot;linkedin&quot;=&gt;&quot;wouter-nivelle-34a90b31&quot;, &quot;email&quot;=&gt;&quot;wouter.nivelle@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Wouter is a Project Manager at Ordina Belgium. Passionate about agile. Eager to share knowledge. Not afraid of challenges. Always interested in learning and discovering new things.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2018-07-03-Agile-DevOps-Summit-Brussels.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-12-experience-agile-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-25-agile-reporting.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-02-12-experience-agile-2019-part-2.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-03-experience-agile-2022.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-19-waterfall-vs-agile.md collection=posts&gt;]}</name><email>wouter.nivelle@ordina.be</email></author><category term="Agile" /><category term="Agile" /><category term="Project Management" /><category term="Waterfall" /><summary type="html"><![CDATA[Waterfall or agile for a new project? Benefits or disadvantages?]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2022-10-19-waterfall-vs-agile/header.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2022-10-19-waterfall-vs-agile/header.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">eXperience Agile 2022</title><link href="https://ordina-jworks.github.io/conference/2022/10/03/experience-agile-2022.html" rel="alternate" type="text/html" title="eXperience Agile 2022" /><published>2022-10-03T00:00:00+00:00</published><updated>2022-10-03T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/conference/2022/10/03/experience-agile-2022</id><content type="html" xml:base="https://ordina-jworks.github.io/conference/2022/10/03/experience-agile-2022.html"><![CDATA[<p>After 2 years of COVID, it was finally time for another conference. I’ve chosen the eXperience Agile conference in Lisbon, Portugal, from 26/09/2022 to 27/09/2022.
It was the 8th edition  of a global conference that focuses on gathering wisdom and best practices on business agility as well as technical agility.
Since I’m working with agile teams, I hoped to gather more knowledge and learn new things to apply to my teams.</p>

<p><img alt="Ready for the start" src="/img/2022-10-03-experience-agile-2022/ready_for_the_start.jpg" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>The first day contained 5 talks, agile safari’s, workshops and lightning talks.
The second day had the same format, but due to flight timings, I couldn’t see them all.</p>

<p>All talks were maximum thirty minutes, so the information was very concise.
In this blogpost, I’ll list some talks I found interesting.</p>

<h1 id="table-of-contents">Table of contents</h1>

<ul>
  <li><a href="#fast-agile-by-ron-quartel">FAST Agile, by Ron Quartel</a></li>
  <li><a href="#optimise-your-neurophysiology-for-agile-thinking-by-delia-mccabe">Optimise your neurophysiology for agile thinking, by Delia McCabe</a></li>
  <li><a href="#practice-does-not-make-perfect-by-gil-broza">Practice does not make perfect, by Gil Broza</a></li>
  <li><a href="#understanding-value-streams-at-the-gemba-by-nigel-thurlow">Understanding value streams at the gemba, by Nigel Thurlow</a></li>
</ul>

<h1 id="fast-agile-by-ron-quartel">FAST Agile, by Ron Quartel</h1>

<p>The full title of the talk was ‘FAST Agile – The New (and Wild) Kid on the Agile Block’.</p>
<blockquote>
  <p>“Fluid Scaling Technology aka FAST Agile, is the outcome of an experiment in radical self-organization at scale. Not only did it work, but we also found it solved many of the issues that come with agile at scale that existing methods face. If you like Dave Snowden’s rewilding agile message, you are likely to see the promise in this radical new way of working built on Open Space Technology. Prepare to be surprised…”</p>
</blockquote>

<p><img alt="FAST Agile" src="/img/2022-10-03-experience-agile-2022/fast_agile.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>During the talk, Ron referred a lot to the Cynefin model by <a href="https://thecynefin.co/about-us/about-cynefin-framework/" target="_blank" rel="noopener noreferrer">Dave Snowden</a>. Explaining that model here would take me too far away from the purpose of this post.
In short, it helps to determine in what situation your company/project/team is (complex, complicated, chaos, obvious). And based on that situation, you can take calculated decisions.</p>

<p>Scrum can then be placed in the space between complicated and complex.
FAST sits in the complex space, next to the chaos border.</p>

<p><img alt="Scrum and FAST in Cynefin" src="/img/2022-10-03-experience-agile-2022/scrum_fast_cynefin.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>Now, what is FAST? It uses the principle of the Open Space Technology, where large groups of people come together, self-organise and set up a planning.
It stands for Fluid Scaling Technology. The A is just there so it sounds better.
How the process works:</p>
<ol>
  <li>It merges teams into a tribe</li>
  <li>Everyone throws their work on a wall</li>
  <li>Everyone self-organizes around the work</li>
  <li>2 days later, everyone meets back and shares their progress</li>
  <li>Repeat from the start</li>
</ol>

<p>It’s an agile method where scaling is built-in. Certain conditions must be met, but that’s also true for Scrum and agile in general.</p>

<p>How does FAST help?</p>
<ul>
  <li>It’s a pure complex system, unlike other scaling methods like SAFe which are complicated in nature. The Cynefin model teaches us that complicated systems must be solved with complicated models, and complex with complex.</li>
  <li>It has been designed to not transform to zombie agile</li>
  <li>It focuses on both Discovery and Delivery while other agile methods focus on Delivery</li>
</ul>

<p>More information on FAST can be found at <a href="https://fluid.scaling.tech/" target="_blank" rel="noopener noreferrer">Fluid Scaling Tech</a>.</p>

<h1 id="optimise-your-neurophysiology-for-agile-thinking-by-delia-mccabe">Optimise your neurophysiology for agile thinking, by Delia McCabe</h1>

<p>A surprising talk about the functioning of the brain and how it correlates with agile.</p>
<blockquote>
  <p>“Thinking occurs across a sensitive and sophisticated neural network. Our neurophysiology depends heavily on lifestyle choices, which include the nutrients we consume. Other lifestyle factors, which include sleep quality, physical activity, and work and relationships, also impact this sophisticated network, although nutrition  forms the foundation of our neurophysiology. It is therefore the first principle we need to address if we aim to maximise cognitive strategies such as agile, creative, and flexible thinking.”</p>
</blockquote>

<p><img alt="Feed your brain" src="/img/2022-10-03-experience-agile-2022/feed_your_brain.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>I was most curious about this talk, as it doesn’t immediately connect with an agile conference. She said it herself that she was surprised to have been invited, but took it as a challenge to explain how the brain works and how that affects the agile way of thinking.</p>

<p>She started the talk with explaining how our brains have evolved to work in a jungle environment, to survive.
But that the current office life is a lot different and our brains have difficulties handling it. Back in the ancient times, stress was present in short bursts (for example when hunting), but not continuously like it is in the current times.</p>

<p>She explained how the brain needs to be nourished correctly in order to be able to receive new information.
If the brain is not nourished properly, it will not be able to create new neural links and thus not process new experiences.
So for example, when you’re explaining something new to another person, if that person’s brain is not nourished as it should be, that person will not process the information correctly, if at all.</p>

<p>More information on this subject can be found at <a href="https://www.lighterbrighteryou.life/" target="_blank" rel="noopener noreferrer">here</a>.</p>

<h1 id="practice-does-not-make-perfect-by-gil-broza">Practice does not make perfect, by Gil Broza</h1>

<p>Almost every company uses agile nowadays. But not everyone gets it right.</p>
<blockquote>
  <p>“These days, almost every organization is on an Agile journey. And yet, most companies have trouble achieving real agility. Why is that? Aren’t the ingredients for effective transformations available to everyone? There is no shortage of motivation, established practices, detailed processes, ever-improving tools, literature, consultants, employees with agile experience, and certifications. Gil Broza, author of “The Agile Mindset” and “The Human Side of Agile”, thinks that one particular ingredient has been overlooked in the mad rush to adopt Agile. In this session, he leads us on an exploration of that ingredient and its crucial role in successful Agile journeys.”</p>
</blockquote>

<p><img alt="Practice does not make perfect" src="/img/2022-10-03-experience-agile-2022/practice_does_not_make_perfect.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>The talk started with the explanation of the logical levels model.
It goes top-down from identity and role, to values and belief, to capability, behaviour and environment.
He gave the following example in his current role:</p>

<p><img alt="Logical levels example" src="/img/2022-10-03-experience-agile-2022/logical_levels.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>He continued explaining the starting point of many agile journeys.</p>

<table>
  <thead>
    <tr>
      <th>Traditional values</th>
      <th>Traditional beliefs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Get it right the first time</td>
      <td>Customers know what they want</td>
    </tr>
    <tr>
      <td>Minimize cost and time</td>
      <td>Putting a plan together is worth it</td>
    </tr>
    <tr>
      <td>Make early commitments</td>
      <td>Okay to have multiple constraints</td>
    </tr>
    <tr>
      <td>Follow industry standards</td>
      <td>People are resources</td>
    </tr>
  </tbody>
</table>

<p>The above is of course not very agile. But it’s a starting point where many organisations started.
He then went on explaining how the above works in the logical levels model and how to adapt it.</p>

<p>But either way, as he stated, “Practices don’t matter, mind-set does”.
A good example is the table below, where you can see that just giving things a different name does not work if the traditional belief stays.</p>

<table>
  <thead>
    <tr>
      <th>Practice/role/artifact</th>
      <th>Was conceived as</th>
      <th>A traditional mindset sees it as</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Daily standup</td>
      <td>Regular check-in to maximize the team’s value output</td>
      <td>Daily status for maximizing work-the-plan</td>
    </tr>
    <tr>
      <td>Product backlog</td>
      <td>Prioritized list of valuable deliverables the team might do</td>
      <td>Project plan</td>
    </tr>
    <tr>
      <td>Pair programming</td>
      <td>Collaboration to minimize the risk of employing humans</td>
      <td>Under-utilization</td>
    </tr>
    <tr>
      <td>Scrum Master</td>
      <td>Servant leader, helping the team succeed as a team</td>
      <td>Project manager, ensures process compliance</td>
    </tr>
    <tr>
      <td>Sprint demo</td>
      <td>Feedback, for adaptation</td>
      <td>Frequent deadline for sign-off, tracking and accountability</td>
    </tr>
  </tbody>
</table>

<p>More information of his talk can be found <a href="https://3pvantage.com/resources/Gil%20Broza%20-%20Practice%20Does%20not%20Make%20Perfect.pdf" target="_blank" rel="noopener noreferrer">here</a>.</p>

<h1 id="understanding-value-streams-at-the-gemba-by-nigel-thurlow">Understanding value streams at the gemba, by Nigel Thurlow</h1>

<p>The full title of this talk was “Understanding value streams at the gemba, not from the office”.</p>
<blockquote>
  <p>“He’ll cover what Lean metrics really are, how scaling should work, take you into queuing theory, and then back to the Genba where the real improvements happen. Learn what a real value stream is and how to uncover the real costs of doing business. This and a whole lot more of mind bending topics.”</p>
</blockquote>

<p><img alt="Value stream mapping" src="/img/2022-10-03-experience-agile-2022/value_stream_mapping.png" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>Now this was a talk that was filled with information. There were 71 (!) slides that had to be told in 30 minutes. That is a lot of information to transfer in a short period of time.
However, Nigel managed to do so quite well.
I’m not going to pretend I understood everything, but it was interesting nonetheless.</p>

<p>He talked about the Flow system, about complex versus complicated environments, about various tools and how they’re only visualisations, etc… .
There was way too much to tell here in this blog post, but I’ll try to share some things I’m going to keep in mind.</p>

<p>Value is cross organisation. You can try to sub-optimize in the IT department, but if you don’t take the other departments with you, the value generated will not be optimal.
The value stream contains all the people, machines, technology and skills needed to complete the end to end product delivery.</p>

<p>Closely tying in to the above is the genba/gemba and real value stream.
He explains that growth, costs, time-to-market and staff attrition are not problems, but outcomes. And that if you want to change those outcomes, you’ll have to change how you do work.
This is where genba comes into play. It’s Japanese for “actual place”.</p>

<p><img alt="Gemba" src="/img/2022-10-03-experience-agile-2022/gemba.jpg" class="image fit" style="margin:0px auto; max-width: 750px;" /></p>

<p>It means you need to go the place in your company where the actual value is created. Nigel explained how he helped to transform a corn factory by actually doing an 8-hour shift on the factory floor.
This gave him better insights in one shift than his previous 3 weeks of observation. This enabled him to make changes to the production line and added value to the company.</p>

<p>More information can be found on <a href="https://nigelthurlow.com/" target="_blank" rel="noopener noreferrer">his website</a>.</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Wouter&quot;, &quot;last_name&quot;=&gt;&quot;Nivelle&quot;, &quot;permalink&quot;=&gt;&quot;/author/wouter-nivelle/&quot;, &quot;avatar&quot;=&gt;&quot;wouter-nivelle.jpg&quot;, &quot;title&quot;=&gt;&quot;Project Manager&quot;, &quot;linkedin&quot;=&gt;&quot;wouter-nivelle-34a90b31&quot;, &quot;email&quot;=&gt;&quot;wouter.nivelle@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Wouter is a Project Manager at Ordina Belgium. Passionate about agile. Eager to share knowledge. Not afraid of challenges. Always interested in learning and discovering new things.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2018-07-03-Agile-DevOps-Summit-Brussels.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-12-experience-agile-2019.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2019-11-25-agile-reporting.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2020-02-12-experience-agile-2019-part-2.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-03-experience-agile-2022.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-10-19-waterfall-vs-agile.md collection=posts&gt;]}</name><email>wouter.nivelle@ordina.be</email></author><category term="Conference" /><category term="Agile" /><category term="Conference" /><summary type="html"><![CDATA[After 2 years of COVID, it was finally time for another conference. I’ve chosen the eXperience Agile conference in Lisbon, Portugal, from 26/09/2022 to 27/09/2022. It was the 8th edition of a global conference that focuses on gathering wisdom and best practices on business agility as well as technical agility. Since I’m working with agile teams, I hoped to gather more knowledge and learn new things to apply to my teams.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2022-10-03-experience-agile-2022/ExperienceAgile2022.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2022-10-03-experience-agile-2022/ExperienceAgile2022.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Snitching On Your Colleagues Using Cloud Magic</title><link href="https://ordina-jworks.github.io/internship/2022/07/07/snitching-on-your-colleagues-using-cloud-magic.html" rel="alternate" type="text/html" title="Snitching On Your Colleagues Using Cloud Magic" /><published>2022-07-07T00:00:00+00:00</published><updated>2022-07-07T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/internship/2022/07/07/snitching-on-your-colleagues-using-cloud-magic</id><content type="html" xml:base="https://ordina-jworks.github.io/internship/2022/07/07/snitching-on-your-colleagues-using-cloud-magic.html"><![CDATA[<h1 id="table-of-contents">Table Of Contents</h1>

<ul>
  <li>
    <p><a href="#introduction">Introduction</a></p>
  </li>
  <li><a href="#the-task-at-hand">The Task At Hand</a></li>
  <li><a href="#exploring-the-environment">Exploring The Environment</a>
    <ul>
      <li><a href="#azure-repos">Azure Repos</a></li>
      <li><a href="#pipeline">Pipeline</a></li>
      <li><a href="#library">Library</a></li>
      <li><a href="#service-connections">Service Connections</a></li>
    </ul>
  </li>
  <li><a href="#into-the-rabbit-hole-setting-up-the-pipeline">Into The Rabbit-Hole : Setting Up The Pipeline</a>
    <ul>
      <li><a href="#before-we-dive-in">Before We Dive In</a></li>
      <li><a href="#basic-tasks">Basic Tasks</a></li>
      <li><a href="#containerization">Containerization</a></li>
      <li><a href="#setting-up-a-cloud-database">Setting Up A Cloud Database</a></li>
      <li><a href="#provisioning-a-cloud-cluster">Provisioning A Cloud Cluster</a></li>
      <li><a href="#giving-a-signal">Giving A Signal</a></li>
      <li><a href="#a-visual-representation">A Visual Representation</a></li>
    </ul>
  </li>
  <li><a href="#out-of-the-frying-pan-and-into-the-fire-creating-our-own-task">Out Of The Frying Pan And Into The Fire: Creating Our Own Task</a>
    <ul>
      <li><a href="#requirements">Requirements</a></li>
      <li><a href="#getting-the-logs">Getting The Logs</a></li>
      <li><a href="#filtering-and-saving-failures">Filtering And Saving Failures</a></li>
      <li><a href="#factory-fresh">Factory Fresh</a></li>
    </ul>
  </li>
  <li><a href="#the-berry-on-top--our-physical-feedback">The Berry On Top: Our Physical Feedback</a>
    <ul>
      <li><a href="#dollar-store-google-assistant">Dollar Store Google Assistant</a></li>
    </ul>
  </li>
  <li><a href="#the-good-the-bad---the-ugly--summary">The Good, The Bad &amp; … The Ugly?</a></li>
</ul>

<h1 id="introduction">Introduction</h1>

<p>7 weeks ago I started my internship at Ordina Mechelen.
I had several project options available all looking to touch new and unknown tech that might be relevant for future operations.</p>

<p>My inner Judas spoke to me when I saw a listing about a project that would shoot toy rockets at developers if they broke a build, and it would provide a great opportunity to pull myself out of my comfort zone focusing more on Devops and Cloud platforms rather than pure programming.
Sadly due to a global hardware shortage the toy rocket launcher was not available for delivery anymore, so I decided to use a raspberry pi to fetch the build logs and convert them into audio using google text to speech.</p>

<h1 id="the-task-at-hand">The Task At Hand</h1>

<p>The project described a ci-cd pipeline that would trigger a raspberry pi once a build fails, then in response the pi would operate a toy rocket launcher unit that would target the developer responsible for breaking the build.
As such the final project can be broken down into these steps:</p>

<ul>
  <li>Create a sacrificial bare-bones spring boot project to put through the ringer</li>
  <li>Create a pipeline which performs some cookie cutter tasks</li>
  <li>Expand pipeline to setup AWS infrastructure</li>
  <li>Expand pipeline to provision said infrastructure</li>
  <li>Create a custom pipeline task to fetch and push build logs</li>
  <li>Configure raspberry pi to host a node.js server</li>
  <li>Listen for new log files</li>
  <li>If new log files have been found, search for error messages and convert those via text to speech(TTS)</li>
  <li>Broadcast the failures of your colleagues</li>
</ul>

<h1 id="exploring-the-environment">Exploring The Environment</h1>
<p>I’m going to dive right into the meat and potatoes of this project and write about the pipeline since the spring boot application does nothing more than display some basic html and runs a couple of unit tests.
The devops environment that was used consisted of a couple of things.</p>
<h3 id="azure-repos">Azure Repos</h3>
<p>A simple git instance on the Azure platform used for version control of our spring boot project.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/repo_position.png" style="margin:0px auto; max-width: 100%;" /></p>

<h3 id="pipeline">Pipeline</h3>
<p>The bread and butter of our operation. Using a data serialization language called yaml we are able to define each individual task we want applied to our code.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/pipeline_position.png" style="margin:0px auto; max-width: 100%;" /></p>

<h3 id="library">Library</h3>
<p>A place to store key value pairs that we can group and later reference in our yaml file.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/library_position.png" style="margin:0px auto; max-width: 100%;" /></p>

<h3 id="service-connections">Service Connections</h3>
<p>Predefined connections to internal (Azure) or external services from which we can later extract credentials to gain access in the pipeline.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/service_connection_position.png" style="margin:0px auto; max-width: 100%;" /></p>

<h1 id="into-the-rabbit-hole-setting-up-the-pipeline">Into The Rabbit-Hole: Setting Up The Pipeline</h1>
<p>In this section I will initially explain how to set up some basic tasks within our yaml file for building and testing. 
Next, I’ll move on to containerizing our build. 
Finally, I’ll explain how I have used IaC (Infrastructure as Code) to firstly spin up an RDS (AWS) instance based on Postgres and secondly use Helm to deploy the application to an EKS (AWS) cluster owned by JWorks.</p>
<h3 id="before-we-dive-in">Before We Dive In</h3>
<p>Before we dive in, there are some nice to know things about the inner workings and structure of a pipeline defined in a yaml file.
I’ll briefly go over some key definitions, so you can follow along when each individual task gets explained.</p>
<ul>
  <li>Triggers :
    <ul>
      <li>Triggers are (like the word implies) what starts a pipeline</li>
      <li>These can be changes in a branch like <strong><em>main</em></strong> or <strong><em>develop</em></strong> but could also be specific events happening in another pipeline such as failed jobs/stages or a specific variable value</li>
    </ul>
  </li>
  <li>Variables :
    <ul>
      <li>A hardcoded variable defined at the start of your pipeline</li>
      <li>A variable group containing secret values like tokens that can not be acquired using service connections</li>
      <li>Both of these options can be defined at the same time or individually and used anywhere in the pipeline including in additional task commands if the task allows it.</li>
    </ul>
  </li>
  <li>Stages :
    <ul>
      <li>Defines what steps your pipeline should take in what order.</li>
      <li>Encapsulation of <strong><em>stage</em></strong> sections</li>
    </ul>
  </li>
  <li>Stage :
    <ul>
      <li>A section of your pipeline</li>
      <li>Can be given a name of your choosing eg: Test,Docker,CloudSetup …</li>
      <li>Encapsulation for <strong><em>jobs</em></strong></li>
    </ul>
  </li>
  <li>Jobs :
    <ul>
      <li>Encapsulation of <strong><em>job</em></strong> sections</li>
    </ul>
  </li>
  <li>Job :
    <ul>
      <li>Can be given a name of your choosing just like the <strong><em>stage</em></strong> section</li>
      <li>Can be given a <strong><em>pool</em></strong> attribute to define which agent OS has to run this job</li>
      <li>Encapsulation of one or more <strong><em>task</em></strong> sections</li>
    </ul>
  </li>
  <li>Task :
    <ul>
      <li>A pre-built or custom-made task to be performed on your pipeline run.</li>
      <li>Has a variety of attributes that can be manually filled up such as credentials or dictating your preferred working directories</li>
    </ul>
  </li>
  <li>Agents :
    <ul>
      <li>A machine hosted by the cloud provider (Azure in our case) that runs on a specific OS</li>
      <li>Defined in the <strong><em>pool</em></strong> attribute of a <strong><em>job</em></strong> or at the start of a pipeline.</li>
      <li>Mostly a clean slate with only some essential software pre-installed eg: Docker</li>
      <li>Gets wiped after use in order to accommodate the next job.</li>
    </ul>
  </li>
</ul>

<p>All of the above gets combined into a structure that resembles following code.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">variables</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">group</span><span class="pi">:</span> <span class="s">my-variable-group</span>

<span class="na">trigger</span><span class="pi">:</span> <span class="s">main</span>

<span class="na">pool</span><span class="pi">:</span>
  <span class="na">vmImage</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>

<span class="na">stages</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">stage</span><span class="pi">:</span>
  <span class="na">jobs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">job</span><span class="pi">:</span> <span class="s">myJob</span>
    <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">script</span><span class="pi">:</span> <span class="s">echo "Hello"</span> 
</code></pre></div></div>

<h3 id="basic-tasks">Basic Tasks</h3>
<p>Following are the pipeline tasks used to test our java project, generate a test rapport and then build it using Maven.</p>
<h4 id="maven-test">Maven Test</h4>
<p>To test our application we will be using JUnit because of the pre-existing support given by Azure. 
This will also generate a test rapport during each pipeline run based on the unit tests defined in our project.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/maven_test.png" style="margin:0px auto; max-width: 50%;" /></p>

<h4 id="maven-build">Maven Build</h4>
<p>A standard task using the Maven goal of ‘package’ which returns a JAR file that can later be used by Docker.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/maven_build.png" style="margin:0px auto; max-width: 50%;" /></p>

<h4 id="copying-and-creating-an-artifact">Copying And Creating An Artifact</h4>
<p>In order to use our build across multiple agents we need to create an artifact out of the build.
This artifact gets stored within the pipeline and can get called upon whenever we please.
We do this by first copying our build to a directory on our agent that functions as the default staging directory for artifacts.
By using a second task we take that build and publish it to our pipeline storage.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/copy_and_publish.png" style="margin:0px auto; max-width: 50%;" /></p>

<h3 id="containerization">Containerization</h3>
<p>Here we use the artifact we created during our last job to create an image and push it to Dockerhub.</p>
<h4 id="fetching-our-artifact">Fetching Our Artifact</h4>
<p>First we have to fetch the artifact that we uploaded to our pipeline and place it in the appropriate directory on our new agent.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/download_artifact.png" style="margin:0px auto; max-width: 50%;" /></p>

<h4 id="creating-an-image">Creating An Image</h4>
<p>Then we use said artifact together with a Dockerfile that was previously placed within our java project to create and upload an image to Dockerhub.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/docker_task.png" style="margin:0px auto; max-width: 50%;" /></p>

<h3 id="setting-up-a-cloud-database">Setting Up A Cloud Database</h3>
<p>In this job we will use Terraform to set up an RDS (AWS) database based on Postgres for our containerized java application.
Our Terraform files are stored in the java project under a folder called infrastructure and can be called upon directly, alternatively a remote folder containing Terraform files can be specified if you want or need to split up your project files.
Credentials needed to get access to AWS services come from a manually pre-defined service connection.</p>
<h4 id="installing-terraform">Installing Terraform</h4>
<p>In order to use Terraform on our agent we have to first install it to our agent since it is not supplied by default.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/terraform_install_task.png" style="margin:0px auto; max-width: 50%;" /></p>

<h4 id="initializing-terraform">Initializing Terraform</h4>
<p>This task performs several initialization steps in order to prepare the current working directory for use with Terraform.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/terraform_init.png" style="margin:0px auto; max-width: 75%;" /></p>

<h4 id="terraform-plan">Terraform Plan</h4>
<p>Plans out what configurations and steps will be made once the apply command is given.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/terraform_plan_task.png" style="margin:0px auto; max-width: 75%;" /></p>

<h4 id="terraform-apply">Terraform Apply</h4>
<p>Excecuting our Terraform plan defined in the previous step.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/terraform_apply.png" style="margin:0px auto; max-width: 75%;" /></p>

<h3 id="provisioning-a-cloud-cluster">Provisioning A Cloud Cluster</h3>
<p>Now that we have an image of our app and place to store data to only one crucial step remains, launching our application.
Our application gets deployed to EKS (Elastic Kubernetes Service) which is another AWS service designed for running cloud based Kubernetes.
In order to do so a Helm chart has been made which like the Terraform files is stored under the infrastructure directory of our project.
These charts are defined in a yaml format where specifications for Kubernetes are being made eg: Name of the app, Kind , Amount of replicas, Image to use …</p>

<h4 id="helm-deploy">Helm Deploy</h4>
<p>Using our Helm chart and a service connection allowing us to deploy to the Jworks cluster, we deploy our application, which gets pulled from Dockerhub, to the “stage-thomas-more” namespace within EKS.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/helm_task.png" style="margin:0px auto; max-width: 75%;" /></p>

<h3 id="giving-a-signal">Giving A Signal</h3>
<p>Now that everything has been set up and all the services are up and running it’s time to give our developers a heads-up.
I did this using a Telegram bot that will broadcast a message for every build that has run.
The bot token was stored in the <strong>library</strong> as a secret key-value pair.</p>
<h4 id="creating-our-bot">Creating Our Bot</h4>
<p>This is a prerequisite if you want to work with Telegram since a bot token and a chat id are required to function.
Telegram has a neat tutorial on how to create your own bot using the “Botfather” which you can find here : <a href="https://core.telegram.org/bots" target="_blank" rel="noopener noreferrer">The Botfather</a></p>
<h4 id="sending-out-notifications">Sending Out Notifications</h4>
<p>Now that we have our bot token and a chat id we can define a message that gets sent everytime the task is reached.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/telegram_task.png" style="margin:0px auto; max-width: 50%;" /></p>

<h3 id="a-visual-representation">A Visual Representation</h3>
<p>Displayed below you will find two images representing the pipeline and the goals they accomplish on the Cloud.</p>

<p>For now pay no attention to the little logo displaying Eric Cartman, this is the image I used to represent my custom task which we will get to in the following section.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/pipeline_flow.png" style="margin:0px auto; max-width: 75%;" /></p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/AWS_diagram_final_image.png" style="margin:0px auto; max-width: 75%;" /></p>

<h1 id="out-of-the-frying-pan-and-into-the-fire-creating-our-own-task">Out Of The Frying Pan And Into The Fire: Creating Our Own Task</h1>
<p>During week 5 all of the above was learned, implemented and configured to a working state so a question was asked by Frederick Bousson the solutions lead at the Jworks Ordina Unit if it was possible to create a custom task for use in the pipeline.</p>

<p>Up for another challenge I stepped into the pretty unexplored (And not fully documented) lands of developing a task for a pipeline.
The main objective of the task is to get the pipeline logs from a predefined pipeline run or from the current one as default.
Those logs get filtered and send to a DynamoDB instance hosted on AWS.</p>

<h4 id="requirements">Requirements</h4>
<ul>
  <li>Node.js</li>
  <li>TFX : A packaging tool</li>
  <li>Microsoft VSS Web Extension SDK package</li>
  <li>Some experience writing in Javascript or Typescript</li>
  <li>A Visual Studio publisher account (free)</li>
</ul>

<h4 id="getting-the-logs">Getting The Logs</h4>
<p>This was done using the Azure Devops REST API: <a href="https://docs.microsoft.com/en-us/rest/api/azure/devops/?view=azure-devops-rest-7.1" target="_blank" rel="noopener noreferrer">Documentation</a></p>

<p>To get builds, a couple of things are required:</p>
<ul>
  <li>The Azure Devops organization name</li>
  <li>The project name</li>
  <li>The build number</li>
  <li>Authorization</li>
</ul>

<p>While the values for point one and two were pretty straightforward gaining access to the <strong>build logs</strong> required a <strong>build id</strong> instead of a <strong>build number</strong> , and since the <strong>build id</strong> can not be traced through the UI of Azure Devops some nested API requests were required.</p>

<p>The Authorization was gained through the creation of a PAT token that can be used as a header in the GET Request.</p>
<h4 id="filtering-and-saving-failures">Filtering And Saving Failures</h4>
<p>Now that we have our desired logs all that remains is filtering, formatting and sending those logs to DynamoDB.
In order to complete this operation the following steps were taken:</p>
<ul>
  <li>Set up authorization in a way that allows developers to use their AWS service connection.</li>
  <li>Use the AWS SDK combined with the credentials from the service connection to authorize the user.</li>
  <li>Filter the received logs which had a format of plain text using regex to find possible error messages</li>
  <li>Format the error messages together with the developer responsible for the build and the time of build.</li>
  <li>Push our formatted object to DynamoDB</li>
</ul>

<h4 id="factory-fresh">Factory Fresh</h4>
<p>Eh Voilà!
Our extension does everything we hoped it would do, so it’s time implement it in our pipeline.</p>

<p>First we compile our Typescript to Javascript since the index.js file is the default node entry point.
We then package our extension, and finally upload it using the management portal where we share it with our organizations of choice.</p>

<p>The result:</p>

<p>In my publisher account:
<img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/custom_task_in_marketplace.png" style="margin:0px auto; max-width: 75%;" /></p>

<p>In the pipeline:
<img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/custom_extension_task.png" style="margin:0px auto; max-width: 50%;" /></p>

<p>Want to check out the code? Take a look at the project repo : <a href="https://github.com/MarienL1995/customTaskPublic" target="_blank" rel="noopener noreferrer">Github</a></p>

<h1 id="the-berry-on-top--our-physical-feedback">The Berry On Top : Our Physical Feedback</h1>
<p>Almost there!
Finally, it is time for the actual dirty work namely snitching on our dear colleagues.
To do this I only needed two things, a raspberry pi and a bluetooth speaker.</p>

<h3 id="dollar-store-google-assistant">Dollar Store Google Assistant</h3>
<p>Initially we had planned to use a toy rocket launcher as our physical feedback machine.
That idea was scrapped however because of a global shortage (or tremendous price increase) for all hardware components.</p>

<p>Next the Google Assistant came to mind which is embedded in Android devices or a Google home speaker.
The problem with this idea unfortunately was that the Google Assistant was never designed to take in text input through an API because devices running Google Assistant had no direct endpoints.
Now we could in fact work around this and set up a Home automation system like Home Assistant or Node Red but this would mean that our speaker could never change location without reconfiguring access to its new network.</p>

<p>A final solution I came up with in secret while my mentor was away on a conference in Valencia, was to run a Node.js server on a Raspberry Pi that after booting takes a reference log from our DynamoDB database.
Every minute it would get the latest log available and compare it to the log it had stored, this way when a difference in logs had been found it knew it was time to call out the developer.</p>

<p>Through a nifty npm package we are able to send our text message that we want converted to an audio file and get an url in return pointing to an audio file.
Using Node file system I programmatically created a text file where each audio url alternated with a path to a local audio file gets written on a line in the previously created text file.
What I had just created was a playlist which dictated the order of audio files to be played.
All I had to do now was hook it up to a media player.</p>

<p><strong><em>note</em></strong>: This not the ideal solution, but it allowed the Pi and speaker to be portable to any location as long as we could connect it to wi-fi.</p>

<p>A succesfull pipeline run broadcast(Sound up):</p>

<div class="responsive-video">
  
    <iframe src="https://www.youtube.com/embed/W4LZsEbTRF4" frameborder="0" allowfullscreen="true"> </iframe>
  
</div>

<p>A failed pipeline run broadcast(Sound up):</p>

<div class="responsive-video">
  
    <iframe src="https://www.youtube.com/embed/6PS0K2zdW-o" frameborder="0" allowfullscreen="true"> </iframe>
  
</div>

<h1 id="the-good-the-bad---the-ugly--summary">The Good, The Bad &amp; … The Ugly? : Summary</h1>

<p>Like I mentioned at the start of this blog, there were a number of different project options to choose from as an internship topic.
The reason I went with the ci-cd route is that I knew it would pull me out of my comfort zone and broaden my view on development in general.</p>

<p>While having touched on basic CLI environments like Docker or Bash it always felt cryptic to use a multitude of flags and if you messed up the error messages weren’t all that clear compared to an error with a web framework like React for example.</p>

<p>After 7 weeks of submerging myself mostly in configuration files like .yaml and .tf(Terraform) combined with CLI tools such as kubectl for Kubernetes, psql for Postgres and AWS CLI for AWS Configuration, I’m glad to say that i feel a lot more at home touching on tools not necessarily meant for pure programming.</p>

<p>For a total recap of tools and software used during the project, I put together the following image.</p>

<p><img class="image fit" src="/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/tech_summary.png" style="margin:0px auto; max-width: 75%;" /></p>

<p>As a final sendoff I want to say a quick thank you to my mentor Nick Geudens for guiding me through the jungle of DevOps and AWS and to Frederick Bousson for coming up with the project and allowing me the opportunity to execute it.</p>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Lander&quot;, &quot;last_name&quot;=&gt;&quot;Marien&quot;, &quot;permalink&quot;=&gt;&quot;/author/lander_marien/&quot;, &quot;avatar&quot;=&gt;&quot;lander_marien.jpg&quot;, &quot;title&quot;=&gt;&quot;Intern&quot;, &quot;linkedin&quot;=&gt;&quot;lander-mariën&quot;, &quot;email&quot;=&gt;&quot;lander.marien@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Lander is a graduating student Programming at Thomas More Campus De Nayer.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2022-07-07-snitching-on-your-colleagues-using-cloud-magic.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2023-05-17-kubecon-2023.md collection=posts&gt;]}</name><email>lander.marien@ordina.be</email></author><category term="Internship" /><category term="Spring" /><category term="Spring Boot" /><category term="Git" /><category term="DevOps" /><category term="Docker" /><category term="Kubernetes" /><category term="Terraform" /><category term="Helm" /><category term="Azure" /><category term="Internet Of Things" /><category term="RaspberryPi" /><category term="Javascript" /><category term="Node.js" /><category term="AWS" /><category term="DynamoDB" /><category term="RDS" /><category term="Postgres" /><summary type="html"><![CDATA[Table Of Contents]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/Betrayal.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2022-07-07-snitching-on-your-colleagues-using-cloud-magic/Betrayal.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Clean Agile - Back to Basics</title><link href="https://ordina-jworks.github.io/leadership/2022/06/30/clean-agile.html" rel="alternate" type="text/html" title="Clean Agile - Back to Basics" /><published>2022-06-30T00:00:00+00:00</published><updated>2022-06-30T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/leadership/2022/06/30/clean-agile</id><content type="html" xml:base="https://ordina-jworks.github.io/leadership/2022/06/30/clean-agile.html"><![CDATA[<h1 id="table-of-contents">Table of contents</h1>
<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#the-reasons-for-agile">The Reasons for Agile</a></li>
  <li><a href="#business-practices">Business Practices</a></li>
  <li><a href="#team-practices">Team Practices</a></li>
  <li><a href="#technical-practices">Technical Practices</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h1 id="introduction">Introduction</h1>

<p>Coming from a non-programming background, I was always interested to hear or learn about Agile methodology but with a fear that Agile vocabulary would be too techy for me. This book helped me to get rid out of my fears once and for all. In addition, having been in a High Performance Team using Agile Methodologies at Ordina for 5 years, “Uncle Bob”(Robert C. Martin) helped me via his <em>Back to Basics</em> book to restructure what I experienced and helped me to create my own lessons learned.</p>

<p>This book is for programmers and non-programmers alike. It aims not to go into technical details but focusses more on explaining what the fundamentals of Agile are.</p>

<p>Agile’s ideology and values emerge from a group of 17 programming experts during the fall of 2000 who were willing to create an alternative of what is called the Scientific Management (which inspired the idea of “Waterfall” development).</p>

<p>Four basic values came out of this gathering and are the central idea of the Agile Manifesto that emerged from that moment:</p>

<ul>
  <li><strong>Individuals and interactions</strong> over processed and tools</li>
  <li><strong>Working software</strong> over comprehensive documentation</li>
  <li><strong>Customer collaboration</strong> over contract negotiation</li>
  <li><strong>Responding to change</strong> over following a plan</li>
</ul>

<p>Uncle Bob then gives as an introduction an Agile overview.
 He does this by responding to the question: <strong>“how do you manage a software project”</strong>.
 Therefore, he uses the metaphor of the Iron Cross, a management trade-off that needs to be done in all projects. One has to pick three out of the four goals: Good, Fast, Cheap, Done , in order to manage a project. Reaching all of these in the project is not possible.</p>

<p><img class="image fit" src="/img/2022-06-30-clean-agile/clean-agile-1.png" style="margin:0px auto; max-width: 100%;" /></p>

<p>In this context, he warns that Agile is not the Holy Grail, but only a framework that helps managers and developers to execute the goals they decide to take on <em>by providing real data</em>. This data is needed to make good decisions. Without data, no project can be well managed.</p>

<p>This way he introduces some Agile tools (known from everyone that already worked with one of the Agile methodologies): burn-down charts, story points, business value, iterations. These have only one goal: every stakeholder of the project has a constant feedback on how it evolutes. These are thus created not to control the team but to make appropriate adjustments to correctly manage the project.</p>

<h1 id="the-reasons-for-agile">The Reasons for Agile</h1>

<p>If you have to read only one chapter of this book, it should be this one. In it, Uncle Bob reminds us that even if many of the Agile tools have been proliferating since 20 years (Scrum, Kanban, XP, SAFe, etc.), it makes no sense to use them without keeping in mind the essence of Agility.</p>

<p>There are the two straightforward reasons of using Agile methodologies: <strong>professionalism</strong> and <strong>reasonable expectations</strong> of our customer.</p>

<ul>
  <li>Professionalism in the sense that developers are those who design today’s world (software is everywhere). And as the quote of the first Spiderman movie warns: <strong>“With great power comes great responsibility”</strong>.</li>
</ul>

<p><img class="image fit" src="/img/2022-06-30-clean-agile/clean-agile-2.jpg" style="margin:0px auto; max-width: 50%;" /></p>

<ul>
  <li>Customers have the right to have Reasonable expectations :
    <ul>
      <li>Continuous technical readiness: in order to counter artificial delays, the system should be technically deployable at the end of each iteration (Clean Code, Automated Testing)</li>
      <li>Stable productivity and inexpensive adaptability: customers and managers don’t expect the project to slow down with time (Continuous Refactoring, Architecture Design, Clean Code)</li>
      <li>Continuous improvement: early problems must fade away and the system should get better and better with time (Pair Programming, TDD, Refactoring, Simple Design)</li>
      <li>Fearless competence: developers do not have to fear touching an ugly code (Clean Code)</li>
      <li>QA should find nothing and Test Automation: If QA finds a problem, development team should figure out what went wrong in the process so that QA finds nothing next time (TDD, Continuous Integration, Acceptance Testing)</li>
      <li>We cover for each other: it is your responsibility to make sure that at least one other team member can cover for you (Pair Programming, Whole Team, Collective Ownership)</li>
      <li>Honest estimates: developers need to provide estimates based on what they do and don’t know (Planning Game, Whole Team)</li>
      <li>You need to say “no”: no matter which pressure is on you, you have to say “no” if the answer is really no (Whole Team)</li>
      <li>Mentoring and continuous aggressive learning: as the industry changes quickly, you should follow this flow and learn to teach (Whole Team)</li>
    </ul>
  </li>
</ul>

<p>In this state of mind, he concludes this chapter with the XP Customer and Developer Bill of Rights:</p>

<p><strong>Customer Bill of Rights</strong></p>

<ul>
  <li>You have the right to an overall plan, to know what can be accomplished when and at what cost.</li>
  <li>You have the right to get the most possible value out of every programming week.</li>
  <li>You have the right to see progress in a running system, proven to work by passing repeatable tests that you specify.</li>
  <li>You have the right to change your mind, to substitute functionality, and to change priorities without paying exorbitant costs.</li>
  <li>You have the right to be informed of schedule changes, in time to choose how to reduce the scope to restore the original date. You can cancel at any time and be left with a useful working system reflecting investment to date.</li>
</ul>

<p><strong>Developer Bill of Rights</strong></p>

<ul>
  <li>You have the right to know what is needed, with clear declarations of priority.</li>
  <li>You have the right to produce quality work at all times.</li>
  <li>You have the right to ask for and receive help from peers, managers, and customers.</li>
  <li>You have the right to make and update your own estimates.</li>
  <li>You have the right to accept your responsibilities instead of having them assigned to you.</li>
</ul>

<p><img class="image fit" src="/img/2022-06-30-clean-agile/clean-agile-3.jpg" style="margin:0px auto; max-width: 100%;" /></p>

<p>Based on those fundamental reasons, the next 3 chapters aim to explain the practices of XP (Business, Team and Technical wise) - keeping in mind that Agile is the foundation of an <strong>ethical</strong> standard of software. Nothing else.</p>

<h1 id="business-practices">Business Practices</h1>

<p>As Uncle Bob reminds, XP Business-facing-practices are including the concepts of Planning, Small Releases, Acceptance Tests and Whole Team.</p>

<ul>
  <li><strong>Planning</strong> and day-to-day management are handled through story points. The concept behind SP is that those points are not estimated time, but estimated effort. The aim for using story points is to give a day-to-day estimation of the workload. Each iteration will help the next iteration to estimate more precisely what still needs to be developed. But, as he highlights: “that estimate is not a promise, and the team has not failed if the velocity is lower. The aim is thus only to produce data necessary to manage the project correctly</li>
  <li><strong>Small releases</strong> practices are handled through the concept of <em>Continuous Delivery</em>. He mentions that nowadays, the best Source Code Control used is Git thanks to some of its characteristics (no checkout time, no conflicts of committing, tiny decoupled modules, rapid commit frequency, fast-running test suite…)</li>
  <li><strong>Acceptance Tests</strong> practices are handled through the concept of <em>Behavior-Driven Development</em> (BDD): The business writes formal tests (Given…, When…, Then…) describing the behavior of each story, and Developers automate those tests, which become the <em>Definition of Done</em></li>
  <li><strong>Whole Team</strong> practice has been conceptualized to cancel the mental separation between the customer and the developers. “A development team is composed of many roles including managers, testers, technical writers, etc.”</li>
</ul>

<p>Business practices have thus one aim: to increase and facilitate communication between business and developers. <strong>“That communication breeds trust”</strong>.</p>

<h1 id="team-practices">Team Practices</h1>

<p>Team practices are aimed at governing the relationship between all team members for the sake of the project they work on. These are composed by: Metaphor, Sustainable Pace, Collective Ownership and Continuous Integration.</p>

<ul>
  <li><strong>Metaphor</strong> practice is the fact that a model (with its own vocabulary) is created to explain the problem domain in order to get <strong>everyone</strong> agreed on it (developers as well as management or customers or..)</li>
  <li><strong>Sustainable Pace</strong> practices remind to keep workload at a life equilibrium, through diminishing as much a possible overtime or “marathons”, and keeping in mind that “sleep is the most precious ingredient in the life of a programmer”</li>
  <li><strong>Collective ownership</strong> practices defines the fact that even if sometimes a developer needs to specialize in a particular domain, he should also generalize, obligating himself to work on other areas of the code, less known for him</li>
  <li><strong>Continuous Integration</strong> practices is the fact that the continuous build should never break</li>
</ul>

<p>For Uncle Bob, these practices “help small teams to behave like true teams”.</p>

<h1 id="technical-practices">Technical Practices</h1>

<p>While these practices are less used by programmers, Uncle Bob pinpoints that they are the very core of Agile and not using them is creating an “ineffective flaccid shell of what it was intended to be”.
 These practices are the following: Test-Driven Development (TDD), Refactoring, Simple Design and Pair Programming.</p>

<ul>
  <li><strong>TDD</strong> practice are for developers what double-entry bookkeeping is for accountants. Uncle Bob reminds the <a href="http://butunclebob.com/ArticleS.UncleBob.TheThreeRulesOfTdd" target="_blank" rel="noopener noreferrer">three rules of TDD</a> but, more important, he explains by an example of how courageous it is to keep the code clean and orderly. Thanks to that, we can act like professionals.</li>
  <li><strong>Refactoring</strong> is the “practice of improving the structure of the code without altering the behavior, as defined by the tests”. In order to do so, he suggests the Red/Green/Refactor cycle, insisting on the 2 separated dimensions that are writing a code that works versus writing a code that is clean.</li>
</ul>

<p><img class="image fit" src="/img/2022-06-30-clean-agile/clean-agile-4.png" style="margin:0px auto; max-width: 100%;" /></p>

<ul>
  <li><strong>Simple design</strong> is the practice based on the 4 Kent Beck’s rules:
    <ul>
      <li>Pass all the tests</li>
      <li>Reveal the intent: being expressive, easy to read</li>
      <li>Remove duplication: the code shouldn’t say the same thing more than once</li>
      <li>Decrease elements (classes, functions, variables, etc)</li>
    </ul>
  </li>
  <li><strong>Pair programming</strong> practice has one goal: to “share and exchange knowledge, not concentrate it”</li>
</ul>

<h1 id="conclusion">Conclusion</h1>

<p>As a conclusion for the book, the 4 core values of Agile are summarized :</p>

<ul>
  <li><strong>Courage</strong>: to say no, to rewrite code, to document well, to test well, to take a step aside, etc. “The belief that quality and discipline increase speed”</li>
  <li><strong>Communication</strong>: whatever form it takes (face-to-face, informal, interpersonal), direct and frequent communication is a must to create a team looking at the same direction</li>
  <li><strong>Feedback</strong>: giving or receiving feedback is what makes a team working efficiently</li>
  <li><strong>Simplicity</strong>: through being direct, with the idea of acknowledging a problem when you know there is one.</li>
</ul>

<p>The next pages and last chapter are designed to give ideas on how Agile values are implemented concretely ( how Agile works in small versus big companies, how to transform a non-Agile company to an Agile company, Coaching, Certification, Agile tools) as well as the next direction Uncle Bob thinks Agile should take (Synergy between Agility and Craftmanship). But for me, at this point we divert from the original purpose of this book, which is to highlight the core values of what Agility is.</p>

<p>I will thus finish this article with one of his sentences that illustrated to me his mindset while reading the book.</p>

<blockquote>
  <p><strong>Agile is a small idea about the small problems of small programming teams doing small things</strong>.</p>
</blockquote>]]></content><author><name>{&quot;first_name&quot;=&gt;&quot;Laura&quot;, &quot;last_name&quot;=&gt;&quot;Prevost&quot;, &quot;permalink&quot;=&gt;&quot;/author/laura-prevost/&quot;, &quot;avatar&quot;=&gt;&quot;laura-prevost.jpg&quot;, &quot;title&quot;=&gt;&quot;Analyst&quot;, &quot;linkedin&quot;=&gt;&quot;laura-prevost-72097255&quot;, &quot;email&quot;=&gt;&quot;laura.prevost@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Laura is an Analyst at Ordina Belgium. Also Competence Lead of Technical Leadership at Jworks. Passionate about people. Eager to share knowledge. Not afraid of challenges. Always interested in learning and discovering new things.&quot;, &quot;posts&quot;=&gt;[#&lt;Jekyll::Document _posts/2022-05-05-collective-intelligence.md collection=posts&gt;, #&lt;Jekyll::Document _posts/2022-06-30-clean-agile.md collection=posts&gt;]}</name><email>laura.prevost@ordina.be</email></author><category term="Leadership" /><category term="Leadership" /><category term="Agile" /><category term="Clean" /><summary type="html"><![CDATA[Table of contents Introduction The Reasons for Agile Business Practices Team Practices Technical Practices Conclusion]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2022-06-30-clean-agile/clean_agile_home.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2022-06-30-clean-agile/clean_agile_home.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>