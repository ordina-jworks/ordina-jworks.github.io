---
layout: post
authors: [dieter_hubau, yannick_de_turck, tom_van_den_bulck , johan_silkens]
title: 'Spring IO 2018'
image: /img/spring-io-2018/spring-io.jpg
tags: [Spring IO,Spring,Java,Conference]
category: Conference
comments: true
---

## Spring IO is back!

TODO: Intro

> TODO: describe venue

****

<img class="image fit" src="{{ '/img/spring-io-2018/springio.jpg' | prepend: site.baseurl }}" alt="Spring IO 2018 Photo Collage" />

****

## Day 1: Talks & Workshops

* [Mark Heckler: Migrating legacy enterprise Java applications to Spring Boot](#mark-heckler-migrating-legacy-enterprise-java-applications-to-spring-boot)
* [Andreas Falker: Spring Security 5 Workshop](#andreas-falker-spring-security-5-workshop)
* [Tommy Ludwig: Observability with Spring based distributed systems](#tommy-ludwig-observability-with-spring-based-distributed-systems)

****

## Mark Heckler: Migrating legacy enterprise Java applications to Spring Boot

You can find him on Twitter at [@mkheckler](https://twitter.com/mkheckler).

- Write schema.sql and data.sql commands to migrate and test database
- Generate skeleton project from start.spring.io
- Use Kotlin to vastly simplify your code
  - data classes to simplify access to members and constructors
  - put constructor definition in the same line as the class definition
- Using Spring Data, no more need to use PersistenceContext or EntityManager
- Using Spring MVC with `@RestController`, no more need to declare `@Produces` or `@Consumes`

### Benefits

- Less code
- Less boilerplate
- Better maintainable code
- Better/more deployment options

## Andreas Falker: Spring Security 5 Workshop

https://andifalk.github.io/spring-security-5-workshop/

## Oliver Gierke: REST beyond the obvious - API design for ever evolving systems

## Jurgen Hoeller: Spring Framework 5 - Hidden Gems

Since almost every feature was backported to 4.3, most of them are already known to the general public.
Though there are 7 areas of refinement within 5.0 that aren’t widely known to the public.

### Commons Logging Bridge

So the Spring team came up with a new dependency called spring-jcl which is actually a reimplementation of a logging bridge.
It is a required dependency and is here to help streamline the logging functionality.
The main difference with this way of working is that you don’t need to go through a dependency hell where you would manually add exclusions to ignore certain logging dependencies.
Just add the logging library to your classpath and everything will switch to the logging implementation of your choice.
It now has first class support for Log4J 2 (version 1 has reached its end of life), SLF4J and JUL.

### Build-Time Components Indexer

The file system traversal for classpath scanning of all packages within the specified base packages using either `<context:component-scan>` or `@ComponentScan` might be slow on startup.
This is especially true if your application is started for a small period of time or where I/O is very expensive.
Think short-running batch processes and functions, or applications being started and stopped on Google App Engine every 2 minutes.
The common solution was to narrow your base packages, or even to fully enumerate your component classes so you would skip scanning all together.
Starting with 5.0 there is a new build-time annotation processor that will generate a META-INF/spring.components file per jar containing all the classes which in turn will be used automatically at runtime for compatible component-scan declarations.

### Nullability

The new version contains comprehensive nullability declarations across the codebase.
Fields, method parameters and method return values are still by default non-null, but now there are individual `@Nullable` declarations for actually nullable return values for example.
For Java this means that we have nullability validation in IntelliJ IDEA and Eclipse.
This allows the Spring Team to find subtle bugs or gaps within the framework's codebase.
It will also allow us as developers to validate our interactions with the Spring APIs.
When you're writing code in Kotlin it will give you straightforward assignments to non-null variables because the Kotlin compiler will only allow assignments for APIs with clear nullability.

### Data Class Binding

Spring Data can now work with immutable classes.
No need for setters anymore since it can work with named constructor arguments!
The property names are matched against the constructor parameter names.
You can do this by explicitly using `@ConstructorProperties`, or they are simply inferred from the class bytecode (if you pass `-parameters` or `-debug` as compilation argument).
This is a perfect match with Kotlin and Lombok data classes where the getter and setters are generated at compile time.

### Programmatic Lookup via ObjectProvider

The `ObjectProvider` is a variant of `ObjectFactory`, which is designed specifically for injection points, allowing for programmatic optionality and lenient not-unique handling.
This class had the following original methods: `@Nullable getIfAvailable()` and `@Nullable getIfUnique()`.
With the new version of Spring these methods have been overloaded with `java.util.function` callbacks which empowers the developer to return a default value instead of returning `null`.

### Refined Resource Interaction

Spring's `Resource` abstraction in core.io has been overhauled to expose the NIO.2 API at application level, eg. `Resource.getReadableChannel()` or `WritableResource.getWritableChannel()`.
They are also using the NIO.2 API internally wherever possible, eg. `FileSystemResource.getInput/OutputStream()` or `FileCopyUtils.copy(File, File)`.

### Asynchronous Execution

Spring 5.0 comes with a couple of interface changes that will help you with asynchrous execution:
- The `ListenableFuture` now has a `completable()` method which exposes the instance as a JDK `CompletableFuture`.
- The `TaskScheduler` interface has new methods as an alternative to `Date` and `long` arguments: `scheduleAtFixedRate(Runnable, Instant, Duration)` and `scheduleWithFixedDelay(Runnable, Instant, Duration)`.
- The new `ScheduledTaskHolder` interface for monitoring the current tasks, eg. `ScheduledTaskRegistrar.getScheduledTasks()` and `ScheduledAnnotationBeanPostProcessor.getScheduledTasks()`.

## Cloud Native with Google Cloud Platform and Spring Boot
### by [Ray Tsang](https://twitter.com/saturnism){:target="_blank"}


- workshop: bit.ly/spring-gcp-lab
- code: https://github.com/saturnism/spring-cloud-gcp-guestbook
- Cloud console: https://console.cloud.google.com/

On the one hand this workshop lowered the entry threshold for newbies.
On the other hand it provided insight about what services Google Cloud has to offer.
Google Spanner, Pub/Sub messaging system, CloudSQL, Runtime Config ... They were all addressed. 

We created a guestbook application which consisted of front and backend microservices.
The workshop builds this up nicely by adding features to the application step by step.
Each step introduces you to another Google Cloud service.
Those of you who want to make the workshop yourself, check out the link above.

#### Google PubSub

What stayed with me is Google's Pub/Sub message-oriented middleware.
A publisher that creates the messages sends them to a topic. 
Consumers can subscribe to this topic to obtain the messages.
Publishers and subscribers are decoupled. Neither of them is required to know the other one.
Subscribers will either pull messages or get messages pushed from the topic.
PubSub messages will be delivered at least once, but can be processed multiple times by different subscribers.
Unprocessed PubSub messages are only kept for 7 days

## Flight of the Flux
### by [Simon Baslé](https://twitter.com/simonbasle){:target="_blank"}

In this session Simon went deeper into the inner workings of [Spring Reactor](https://projectreactor.io/) where nothing happens unless you subscribe.
Only after subscription the reactive framework will start to execute your logic

He uploaded his presentation on [speakerdeck](https://speakerdeck.com/simonbasle/flight-of-the-flux?slide=1)


## (Spring)Kafka - One more arsenal in a distributed toolbox
### by [Nakul Mishra](https://twitter.com/nklmish){:target="_blank"}

The slides of this presentation can be found at [slideshare](https://www.slideshare.net/nklmish/springkafka-one-more-arsenal-in-a-distributed-toolbox/)


## Breaking down monoliths into system of systems - Oliver Gierke
### by [Oliver Gierke](https://twitter.com/olivergierke){:target="_blank"}

The goal of this workshop is not to provide a clear architecture of the perfect application, but more to make you think.
To let you reflect about your existing application.

This talk can also be found in shorter iterations like [here](https://www.youtube.com/watch?v=VWefNT8Lb74)
But now is was not a mere hour, but 2 full hours.
Giving us the possibility to have a more in depth look of the prepared code and look into potential problems which might be glossed over when the talk is shorter.

It is a summary of observations about monoliths and microservices.

It all tends to boil down to bounded contexts within applications, how you can divide your application in logical modules and how these can communicate with each other.

First we will observe what happens when a monolith is transformed into a microlith, a distributed monolith.
Subsequently we will improve the design of the monolith with these bounded contexts and come to a modulith.
Which is still a monolith, but with different bounded contexts with clearly defined borders allowing us to easier dived the work over various teams.

From a modulith one can go to a system of sytems, a true microservice architecture.
For a system of systems there are 2 ways you can implement the communication, either via messaging or via rest.

The sample code of this workshop can be found on [https://github.com/olivergierke/sos](https://github.com/olivergierke/sos)

### Monolith
[example code](https://github.com/olivergierke/sos/tree/master/00-monolith)

The monolith is reasonably ordered and the bounded contexts have been split in various packages.

Make optimal use of the package options provided by Java as mentioned in this [blog](http://olivergierke.de/2013/01/whoops-where-did-my-architecture-go/) of 2013: 

Make your code package protected whenever it does not need to be accessed from the outside, a good starting point is to make your repositories no longer public.

Whenever there is leakage over the bounded contexts, for example the Linitems contains Products, try to used ids and not the objects of another bounded context.
Because whenever you update an object used within another bounded context you will also leak into that context.

It is also noted that badly structured applications tend to be built from the bottom up, from db to the top.

Also try to prevent to use methods which update 2 bounded contexts simultaneously, as these methods have the reflex of drawing more and more code in. 
They tend to grow like a cancer.

In short, the following design decisions should be made:
- move bounded contexts into packages.
- inter context interaction is processed locally and resulting in either success or an exception (in jvm method calls are also very efficient and executed exactly once)
- avoid to domain classes reference each other over bounded contexts, but it tends to be convenient. (-)
- when you leak into other bounded contexts there is also a great risk on circular dependencies. (-)
- whenever you need to add a new feature, you tent to need to touch other parts of the system as well, because there are no clear boundaries. (-)
- a monolith is easy to refactor (+)
- it has strong consistency (+) but this is also a disadvantage as transactions become more brittle when they fail because of related business funcionality (-). 


### Microlith
[example code](https://github.com/olivergierke/sos/tree/master/10-microlith)

With a microlith you will split up your systems into various smaller systems.

Whenever you managed to transform your monolith to microservices you tend to think that all your problems have been solved.

However if it has become a monolith you will have the following problems:
- No longer able to use local transaction consistency
- Local method invocation is transformed into RPC-ish HTTP calls.
- You have translated the transactions of your monolith into a distributed system, needing HTTP to update each other.
- Remote calls are executed while serving user requests and this over multiple services.
- Running and testing requires the other services to be available.
- There is a strong focus on API contracts, which tend to be very CRUD-y with a lack of business abstraction and hypermedia.
- Detecting breaking API changes is prioritized over making evolvable api's.
- One tends to add more technology in order to solve issues: bulkheads, retries, circuit breakers, asynchronous calls, more monitoring systems, ...

It tends to minimize the risks of a rollback, but it does not really solve any issue, it just distributes your problems.

### Modulith
[example code](https://github.com/olivergierke/sos/tree/master/20-modulith)

With the modulith we will start to use events within the monolith.

Also we will start to use more domain specific methods, like an add() on an Order, as this makes the whole more abstract and your domain objects become more then glorified getters and setters.

#### Side Step: Application Events with Spring Data
This is a very powerfull mechanism to publish events in a Spring application.

Whenever you need to send data to another bounded context you trigger events.
This has the advantage that your business services no longer need to know about each other anymore, they just need to trigger an event which gets picked up by the services which are interested in this event.

Transactional semantics are still retained because the eventing is synchronous, by default.
This also applies for JEE eventing.

The [@TransactionalEventListener](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/event/TransactionalEventListener.html) annotation allows you to delay the executiong of events, so for example, you can send out an email when the Order has truly been completed.

We are not doing CQRS or event sourcing, but we just use eventing as a way to signal events over bounded contexts.

The differences with a monolith are:
- Focus of domain logic has moved to aggregates.
- Integration between bounded contexts is event based.
- The dependency between bounded contexts is inverted.

#### Side Step: Error Scenarios
When a synchronous event listener fails, this will be handled by the transaction, so no worries.

But when an asynchronous event listener fails, the transaction does not get rolled back and you will need to deal with retries.

You can make use of an Event Publication Registry when you use of [TransactionalEventListeners](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/event/TransactionalEventListener.html) as these event listeners are decorated with a log, before the commit because the system needs to know to where the events need to be sent out.
When the event has been processed, the log will be cleared, if it does not get cleared the system can keep retrying. 
So you do not lose events.

### System of Systems
[with messaging](https://github.com/olivergierke/sos/tree/master/30-messaging-sos)
[with REST](https://github.com/olivergierke/sos/tree/master/40-restful-sos)


#### Messaging
Whenever you make use of a message broker you do introduce a potentional single point of failure, like with [Apache Kafka](https://kafka.apache.org/) or [RabbitMQ](https://www.rabbitmq.com/).
These brokes know about all messages of all systems and decide how long these messages will be retained.

Coupling does exist, although not explicit, but the message format will decide which version of a service can process these messages, just as with REST.
Especially if you keep your events for a long time, which is possible with Kafka, you might need to think about transforming existing events. 

But these messaging systems tend to be designed for scale.

Pro tip: make use of [JsonPath](https://github.com/json-path/JsonPath) annotations for the message payload in order to make it more robust.

#### REST Messaging
If you use REST you will have to deal with caching, pagination and conditional requests.

Messages do not tend to be stored for long periods of time and most communication tends to be synchronous.
One does have to pay attention on not to lose events.


#### REST Polling
With polling your produces do not send out messages to your consumers, but the consumers will poll the producers for new events they can process.

This means that:
- You do not need additional infrastructure.
- Event publication is part of the local transaction.
- The publishing system, producer, controls the lifecycle of the events.
- The events never leave the publishing system.
- There might be a bigger consistency gap, depending on how frequently the consumers poll (-)
- It does not scale that well.


### Conclusion
All in all a great workshop which makes you ponder about the design decisions you have made for your applications. If you can ever participate at one of these workshops, do not hesitate but join it.

## Tommy Ludwig: Observability with Spring based distributed systems

<span class="image left"><img class="p-image" alt="Tommy Ludwig" src="/img/spring-io-2018/tommy-ludwig.jpg"></span>

### Introduction

[Tommy](https://twitter.com/tommyludwig){:target="blank"}'s talk introduced three main pillars of observability: logging, metrics, and tracing.

Tommy explained that observability is achieved through a set of tools and practices that aim to turn data points and contexts into insights.
Observability is something you should care about as it provides a great experience for the users of your system and it builds confidence in production where failure **will** happen.
You ought to give yourself the tools you need in order to be a good owner in order to detect this failures as early as possible.
Mean time to recovery is key here.
He also quoted Werner Vogels's, the CEO of Amazon, "You build it, you run it" while also adding to it that you need to monitor it.

Within a Spring Boot project, we have access to Actuator and it is awesome.
It comes with a lot of goodies out of the box.
There is also [Spring Boot Admin](https://github.com/codecentric/spring-boot-admin){:target="_blank"} that makes it easy to access and use each instance's Actuator endpoints.

Distributed systems make observing them hard by design as a request spans multiple processes.
You therefore need to stitch these together in order to fully make sense of it.
There are also more points of failure and adding multiple instances of the same service, for scaling reasons, will only increase the monitoring complexity.

Tommy named three sides to observability:
* Logging
* Metrics
* Tracing

### Logging
Logs are request scoped, arbitrary messages that you want to find back later.
They are formatted to give you context via things such as logging levels and the timestamp.
The issue with logs is that they do not scale, concurrent requests intermingle logs, and searching through them can be cumbersome.
In order to tackle these issues you can make use of centralized logging while also adding a query capability to retrieve a collection of matching logs.
Within Spring Boot we can configure the logging via Spring Environment and via Actuator at runtime.
[Spring Cloud Sleuth](https://cloud.spring.io/spring-cloud-sleuth/){:target="_blank"} is useful to add a trace ID for request correlation.

### Metrics
Metrics aggregate time series data and have a bounded size.
You can slice these based on dimensions, tags and labels.
The main goal of metrics is to visualize and identify trends and deviations, and to raise alerts based on metric queries.
Some examples of metrics are: response time, the response's body size and memory consumed.
In order to properly measure all this, you need to set up a metrics backend to which all applications publish their metrics data.
In Spring Boot 2, [Micrometer](https://github.com/micrometer-metrics/micrometer){:target="_blank"} is introduced as its native metrics library.
Micrometer supports many metrics backends such as Atlas Datadog, Prometheus, SignalFX and Wavefront.
A lot of the instrumentation is auto-configured by Spring Boot and custom metrics are easy to add.
These are configurable via properties and common tags such as the application name, the instance, region, zone, and more.

### Tracing
Local tracing happens via the Actuator `/httptrace` endpoint and displays the latency data.
With distributed tracing you can go across process boundaries which is useful as metrics lack request context and as logs have a local context but limited distributed info.
You define the sample of how many request to trace yourself as you don't want to trace everything especially if you have a high load.
[Zipkin](https://zipkin.io){:target="_blank"} with its UI helps you to see the timing information visually and is a good tracing backend for Spring applications.
Using Spring Cloud Sleuth, it auto-configured the tracing instrumentation via [Zipkin's Brave](https://github.com/openzipkin/brave){:target="_blank"}.
Via properties you can configure things such as the sampling probability and whether certain endpoints should to be skipped.

### Correlation everywhere
Having set up all of these, you now have correlated logging, metrics and tracing across your system, and you can find the data from each based on identifiers.

### Observability cycle
If an issue produces itself we can take the following steps to troubleshoot and bandage the situation:
* The issue should've been reported via an alert or report
* We check the metrics of our system
* If needed, we check the tracing data
* If needed, we check the logs
* Based on the gathered information we can triage the issue and make adjustments to prevent a recurrence

### Key takeaways
System wide observability is crucial in distributed architectures.
The tools to help you with this exist and Spring makes it easy to integrate them in your system as the most common cases are covered out-of-the-box or easily configurable.
Use the right tool for the job and synergise across the different tools.

## Day 2: Talks & Workshops

- [James Weaver: Machine Learning exposed: The fundamentals](#james-weaver-machine-learning-exposed)
- [Joe Grandja: Next generation OAuth support with Spring Security 5  ](#joe-grandja-next-generation-oauth-springsec5)
- [Jeroen Sterken & Kristof Van Sever: Testing every level of spring microservices application (Workshop)  ](#joe-grandja-next-generation-oauth-springsec5)

## Machine learning exposed: The fundamentals
**By [James Weaver](https://twitter.com/JavaFXpert) (Pivotal)**

Machine Learning is a hot topic in tech land nowadays with all kinds of applications like predicting property prices, forecasting weather , self driving cars , plants classification and so on. James gave a brief overview about the fundamentals of Machine Learning and it's applications. 

But how can we define Machine Learning? [Andrew Ng](https://twitter.com/AndrewYNg), Co-founder of Coursera and Adjunct Professor of Stanford University defined Machine learning in his introduction course "Welcome To Machine Learning"  <sup>1</sup> as "*Machine Learning is the science of getting computers to learn, without being explicitly programmed*". An example that Andrew gave was a cleaning robot that can tidy your house. Instead you program the algorithm explicitly on how it should clean. You can for instance let the robot watch you while you demonstrate the tasks on how it should clean and learn from it.

Later on he gave examples of different categories of machine learning.

### Categories of Machine Learning

#### Supervised learning
 
This was the category where James gave the most examples of during his talk . Supervised learning is where you train your model with a data set wich contains the inital data and it's correct answers. The more training data you have, the more accurate your predictions will be.

##### Regression example

An example he showed us was the prediction of house prices using regression.
<span class="image center"><img class="p-image" alt="House price prediction (From Andrew Ng Learning course)" src="/img/spring-io-2018/houseprice.png" class="image fit" style="max-height:'476px'; max-width='876px'">
<small class="center">(From Andrew NG's Machine learning course)</small></span>

In this example, the data set consists of instances with a square footage (input) and price (output). With a regression, we can predict a continuous valued price.
##### Classification example

<div class="row"><span class="image left"><img alt="Iris flower classification using machine learning" src="/img/spring-io-2018/iris-dataset.png" class="image fit" style="max-width='374.5px'; max-height='374.5px;'">
<small>Source:<a href="https://en.wikipedia.org/wiki/User:Nicoguaro/Gallery">Nicoguaro's Wikipedia media gallery</a> (CC BY 4.0) An example of Supervised Learning using classification </small></span>
<span class="image right"><img alt="Iris flower classification using machine learning" src="/img/spring-io-2018/test-data.png" cslass="image fit">
<small></small></span></div>

Another example of Supervised Learning is to determine a certain species of an Iris flower. Your algorithm must try to determine the species with the Sepal and Petal size of a flower as input.  

 
	 
#### Unsupervised Learning 

For Unsupervised learning on the other hand, you don't give the right answers with your dataset. Your learning algorithm will try to find a structure in the given data.

A method to try to find a structure, is to do it by clustering. So your data is 'grouped' is clusters together with data that more or less belongs to each other. Market segment discovery and social media analysis are examples of Unsupervised Learning
#### Reinforcement Learning

By Reinforcement Learning, you give your algorithm rewards when it did something well. This type of learning is very popular in game playing. AlphaGo for example from Google Deepmind was thaught by Reinforcement Learning


### Neural networks

<span class="image left"><img alt="Neural network example" src="/img/spring-io-2018/neural-network.png" class="image">An example neural network</span>
<br/>
<br/>  
The second part of his talk was about Neural Networks. (Artificial) Neural Networks are computing systems that are inspired of biological neural networks. It's made up of highly interconnected processing elements or 'nodes' that can process information. An Neural Network consists of different layers. An input layer, one or more hidden layers and an output layer.

We can visually demonstrate on how Neural Networks work with the help of deeplearning4j. You can clone and try out his example on[ https://github.com/JavaFXpert/visual-neural-net-server](https://github.com/JavaFXpert/visual-neural-net-server) 

Let's use the flower classification example with our neural network.
<span class="image center"><img alt="Iris flower classification Neural Network Example" src="/img/spring-io-2018/iris-flower-neural-network.png" class="image fit"></span>

 


<small> [1: Welcome to Machine Learning (Andrew Ng) ](https://www.coursera.org/learn/machine-learning/lecture/zcAuT/welcome-to-machine-learning) </small>   




## Next generation OAuth support with Spring Security 5
**By [Joe Grandja](https://www.linkedin.com/in/joegrandja/) (Pivotal)**

TODO

## Testing every level of your Spring Microservices application (Workshops)
**By [Jeroen Sterken](https://twitter.com/jeroensterken) & [Kristof Van Sever](https://twitter.com/vanseverk) (Faros NV)**

 Presentation and course material can be found here
  
 - [https://github.com/faros/bdd-cucumber](https://github.com/faros/bdd-cucumber)
 - [https://github.com/faros/spring-cloud-contract](https://github.com/faros/spring-cloud-contract)



## Got triggered?

All talks were recorded by the Spring IO team. You can view them [here](https://www.youtube.com/channel/UCLMPXsvSrhNPN3i9h-u8PYg).

****
