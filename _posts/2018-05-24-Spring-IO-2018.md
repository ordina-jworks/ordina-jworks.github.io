---
layout: post
authors: [dieter_hubau, yannick_de_turck, tom_van_den_bulck]
title: 'Spring IO 2018'
image: /img/spring-io-2018/spring-io.jpg
tags: [Spring IO,Spring,Java,Conference]
category: Conference
comments: true
---

## Spring IO is back!

TODO: Intro

> TODO: describe venue

****

<img class="image fit" src="{{ '/img/spring-io-2018/springio.jpg' | prepend: site.baseurl }}" alt="Spring IO 2018 Photo Collage" />

****

## Day 1: Talks

* [Mark Heckler: Migrating legacy enterprise Java applications to Spring Boot](#mark-heckler-migrating-legacy-enterprise-java-applications-to-spring-boot)
* [Andreas Falker: Spring Security 5 Workshop](#andreas-falker-spring-security-5-workshop)
* [Tommy Ludwig: Observability with Spring based distributed systems](#tommy-ludwig-observability-with-spring-based-distributed-systems)

****

## Mark Heckler: Migrating legacy enterprise Java applications to Spring Boot

You can find him on Twitter at [@mkheckler](https://twitter.com/mkheckler).

- Write schema.sql and data.sql commands to migrate and test database
- Generate skeleton project from start.spring.io
- Use Kotlin to vastly simplify your code
  - data classes to simplify access to members and constructors
  - put constructor definition in the same line as the class definition
- Using Spring Data, no more need to use PersistenceContext or EntityManager
- Using Spring MVC with `@RestController`, no more need to declare `@Produces` or `@Consumes`

### Benefits

- Less code
- Less boilerplate
- Better maintainable code
- Better/more deployment options

## Andreas Falker: Spring Security 5 Workshop

https://andifalk.github.io/spring-security-5-workshop/

## Oliver Gierke: REST beyond the obvious - API design for ever evolving systems

## Jurgen Hoeller: Spring Framework 5 - Hidden Gems

Since almost every feature was backported to 4.3, most of them are already known to the general public.
Though there are 7 areas of refinement within 5.0 that aren’t widely known to the public.

### Commons Logging Bridge

So the Spring team came up with a new dependency called spring-jcl which is actually a reimplementation of a logging bridge.
It is a required dependency and is here to help streamline the logging functionality.
The main difference with this way of working is that you don’t need to go through a dependency hell where you would manually add exclusions to ignore certain logging dependencies.
Just add the logging library to your classpath and everything will switch to the logging implementation of your choice.
It now has first class support for Log4J 2 (version 1 has reached its end of life), SLF4J and JUL.

### Build-Time Components Indexer

The file system traversal for classpath scanning of all packages within the specified base packages using either `<context:component-scan>` or `@ComponentScan` might be slow on startup.
This is especially true if your application is started for a small period of time or where I/O is very expensive.
Think short-running batch processes and functions, or applications being started and stopped on Google App Engine every 2 minutes.
The common solution was to narrow your base packages, or even to fully enumerate your component classes so you would skip scanning all together.
Starting with 5.0 there is a new build-time annotation processor that will generate a META-INF/spring.components file per jar containing all the classes which in turn will be used automatically at runtime for compatible component-scan declarations.

### Nullability

The new version contains comprehensive nullability declarations across the codebase.
Fields, method parameters and method return values are still by default non-null, but now there are individual `@Nullable` declarations for actually nullable return values for example.
For Java this means that we have nullability validation in IntelliJ IDEA and Eclipse.
This allows the Spring Team to find subtle bugs or gaps within the framework's codebase.
It will also allow us as developers to validate our interactions with the Spring APIs.
When you're writing code in Kotlin it will give you straightforward assignments to non-null variables because the Kotlin compiler will only allow assignments for APIs with clear nullability.

### Data Class Binding

Spring Data can now work with immutable classes.
No need for setters anymore since it can work with named constructor arguments!
The property names are matched against the constructor parameter names.
You can do this by explicitly using `@ConstructorProperties`, or they are simply inferred from the class bytecode (if you pass `-parameters` or `-debug` as compilation argument).
This is a perfect match with Kotlin and Lombok data classes where the getter and setters are generated at compile time.

### Programmatic Lookup via ObjectProvider

The `ObjectProvider` is a variant of `ObjectFactory`, which is designed specifically for injection points, allowing for programmatic optionality and lenient not-unique handling.
This class had the following original methods: `@Nullable getIfAvailable()` and `@Nullable getIfUnique()`.
With the new version of Spring these methods have been overloaded with `java.util.function` callbacks which empowers the developer to return a default value instead of returning `null`.

### Refined Resource Interaction

Spring's `Resource` abstraction in core.io has been overhauled to expose the NIO.2 API at application level, eg. `Resource.getReadableChannel()` or `WritableResource.getWritableChannel()`.
They are also using the NIO.2 API internally wherever possible, eg. `FileSystemResource.getInput/OutputStream()` or `FileCopyUtils.copy(File, File)`.

### Asynchronous Execution

Spring 5.0 comes with a couple of interface changes that will help you with asynchrous execution:
- The `ListenableFuture` now has a `completable()` method which exposes the instance as a JDK `CompletableFuture`.
- The `TaskScheduler` interface has new methods as an alternative to `Date` and `long` arguments: `scheduleAtFixedRate(Runnable, Instant, Duration)` and `scheduleWithFixedDelay(Runnable, Instant, Duration)`.
- The new `ScheduledTaskHolder` interface for monitoring the current tasks, eg. `ScheduledTaskRegistrar.getScheduledTasks()` and `ScheduledAnnotationBeanPostProcessor.getScheduledTasks()`.

## Cloud Native with Google Cloud Platform and Spring Boot
### by [Ray Tsang](https://twitter.com/saturnism){:target="_blank"}


- workshop: bit.ly/spring-gcp-lab
- code: https://github.com/saturnism/spring-cloud-gcp-guestbook
- Cloud console: https://console.cloud.google.com/

On the one hand this workshop lowered the entry threshold for newbies.
On the other hand it provided insight about what services Google Cloud has to offer.
Google Spanner, Pub/Sub messaging system, CloudSQL, Runtime Config ... They were all addressed. 

We created a guestbook application which consisted of front and backend microservices.
The workshop builds this up nicely by adding features to the application step by step.
Each step introduces you to another Google Cloud service.
Those of you who want to make the workshop yourself, check out the link above.

#### Google PubSub

What stayed with me is Google's Pub/Sub message-oriented middleware.
A publisher that creates the messages sends them to a topic. 
Consumers can subscribe to this topic to obtain the messages.
Publishers and subscribers are decoupled. Neither of them is required to know the other one.
Subscribers will either pull messages or get messages pushed from the topic.
PubSub messages will be delivered at least once, but can be processed multiple times by different subscribers.
Unprocessed PubSub messages are only kept for 7 days


## Breaking down monoliths into system of systems - Oliver Gierke

The goal of this workshop is not to provide a clear architecture of the perfect application, but more to make you think.
To let you reflect about your existing application.

This talk can also be found in shorter iterations like [here](https://www.youtube.com/watch?v=VWefNT8Lb74)
But now is was not a mere hour, but 2 full hours.
Giving us the possibility to have a more in depth look of the prepared code and look into potential problems which might be glossed over when the talk is shorter.

It is a summary of observations about monoliths and microservices.

It all tends to boil down to bounded contexts within applications, how you can divide your application in logical modules and how these can communicate with each other.

First we will observe what happens when a monolith is transformed into a microlith, a distributed monolith.
Subsequently we will improve the design of the monolith with these bounded contexts and come to a modulith.
Which is still a monolith, but with different bounded contexts with clearly defined borders allowing us to easier dived the work over various teams.

From a modulith one can go to a system of sytems, a true microservice architecture.
For a system of systems there are 2 ways you can implement the communication, either via messaging or via rest.

The sample code of this workshop can be found on [https://github.com/olivergierke/sos](https://github.com/olivergierke/sos)


### Monolith
[example code](https://github.com/olivergierke/sos/tree/master/00-monolith)

The monolith is reasonably ordered and the bounded contexts have been split in various packages.

Make optimal use of the package options provided by Java as mentioned in this [blog](http://olivergierke.de/2013/01/whoops-where-did-my-architecture-go/) of 2013: 

Make your code package protected whenever it does not need to be accessed from the outside, a good starting point is to make your repositories no longer public.

Whenever there is leakage over the bounded contexts, for example the Linitems contains Products, try to used ids and not the objects of another bounded context.
Because whenever you update an object used within another bounded context you will also leak into that context.

It is also noted that badly structured applications tend to be built from the bottom up, from db to the top.

Also try to prevent to use methods which update 2 bounded contexts simultaneously, as these methods have the reflex of drawing more and more code in. 
They tend to grow like a cancer.

In short, the following design decisions should be made:
- move bounded contexts into packages.
- inter context interaction is processed locally and resulting in either success or an exception (in jvm method calls are also very efficient and executed exactly once)
- avoid to domain classes reference each other over bounded contexts, but it tends to be convenient. (-)
- when you leak into other bounded contexts there is also a great risk on circular dependencies. (-)
- whenever you need to add a new feature, you tent to need to touch other parts of the system as well, because there are no clear boundaries. (-)
- a monolith is easy to refactor (+)
- it has strong consistency (+) but this is also a disadvantage as transactions become more brittle when they fail because of related business funcionality (-). 


### Microlith
[example code](https://github.com/olivergierke/sos/tree/master/10-microlith)

With a microlith you will split up your systems into various smaller systems.

Whenever you managed to transform your monolith to microservices you tend to think that all your problems have been solved.

However if it has become a monolith you will have the following problems:
- No longer able to use local transaction consistency
- Local method invocation is transformed into RPC-ish HTTP calls.
- You have translated the transactions of your monolith into a distributed system, needing HTTP to update each other.
- Remote calls are executed while serving user requests and this over multiple services.
- Running and testing requires the other services to be available.
- There is a strong focus on API contracts, which tend to be very CRUD-y with a lack of business abstraction and hypermedia.
- Detecting breaking API changes is prioritized over making evolvable api's.
- One tends to add more technology in order to solve issues: bulkheads, retries, circuit breakers, asynchronous calls, more monitoring systems, ...

It tends to minimize the risks of a rollback, but it does not really solve any issue, it just distributes your problems.

### Modulith
[example code](https://github.com/olivergierke/sos/tree/master/20-modulith)

With the modulith we will start to use events within the monolith.

Also we will start to use more domain specific methods, like an add() on an Order, as this makes the whole more abstract and your domain objects become more then glorified getters and setters.

#### Side Step: Application Events with Spring Data
This is a very powerfull mechanism to publish events in a Spring application.




Whenever you need to send data to another bounded context you trigger events.
This has the advantage that your business services no longer need to know about each other anymore, they just need to trigger an event which gets picked up by the services which are interested in this event.

Transactional semantics are still retained because the eventing is synchronous, by default.
This also applies for JEE eventing.

The [@TransactionalEventListener](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/event/TransactionalEventListener.html) annotation allows you to delay the executiong of events, so for example, you can send out an email when the Order has truly been completed.

We are not doing CQRS or event sourcing, but we just use eventing as a way to signal events over bounded contexts.

The differences with a monolith are:
- Focus of domain logic has moved to aggregates.
- Integration between bounded contexts is event based.
- The dependency between bounded contexts is inverted.


#### Side Step: Error Scenarios
When a synchronous event listener fails, this will be handled by the transaction, so no worries.

But when an asynchronous event listener fails, the transaction does not get rolled back and you will need to deal with retries.

You can make use of an Event Publication Registry when you use of [TransactionalEventListeners](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/event/TransactionalEventListener.html) as these event listeners are decorated with a log, before the commit because the system needs to know to where the events need to be sent out.
When the event has been processed, the log will be cleared, if it does not get cleared the system can keep retrying. 
So you do not lose events.




### System of Systems
[with messaging](https://github.com/olivergierke/sos/tree/master/30-messaging-sos)
[with REST](https://github.com/olivergierke/sos/tree/master/40-restful-sos)


#### Messaging
Whenever you make use of a message broker you do introduce a potentional single point of failure, like with [Apache Kafka](https://kafka.apache.org/) or [RabbitMQ](https://www.rabbitmq.com/).
These brokes know about all messages of all systems and decide how long these messages will be retained.

Coupling does exist, although not explicit, but the message format will decide which version of a service can process these messages, just as with REST.
Especially if you keep your events for a long time, which is possible with Kafka, you might need to think about transforming existing events. 

But these messaging systems tend to be designed for scale.

Pro tip: make use of [JsonPath](https://github.com/json-path/JsonPath) annotations for the message payload in order to make it more robust.

#### REST Messaging
If you use REST you will have to deal with caching, pagination and conditional requests.

Messages do not tend to be stored for long periods of time and most communication tends to be synchronous.
One does have to pay attention on not to lose events.


#### REST Polling
With polling your produces do not send out messages to your consumers, but the consumers will poll the producers for new events they can process.

This means that:
- You do not need additional infrastructure.
- Event publication is part of the local transaction.
- The publishing system, producer, controls the lifecycle of the events.
- The events never leave the publishing system.
- There might be a bigger consistency gap, depending on how frequently the consumers poll (-)
- It does not scale that well.



monolith -> microlith

monolith -> modulith -> system of systems (using messages, REST)

https://github.com/olivergierke/sos

- design patterns and strategies
- in the monolith:
  - reflect bounded contexts in the packages of your app
  - inter-context interaction is process local (easy so tempting to keep doing)
  - domain classes reference each other across bounded contexts
  - order context calls inventory context directly
  - services become centers of gravity
  - it is easy to refactor
  - strong consistency across bounded contexts (eg. thanks to transactions)
  - order mgmt becomes central hub across all contexts
- microlith: splitting up the system into smaller systems:
  - you need HTTP calls to update each other
  - unsafe, not foolproof, not easily repeatable, more error scenarios
  - marshalling / unmarshalling, networking, ...
  - add more technology to solve issues: bulkheads, retries, circuit breaker, asynchronous calls, scatter gather, ...
  - simple, local consistency is gone
  - local method invocation is transformed into RPC-ish HTTP call
  - all systems need to know all other invoked systems -> more technology (Eureka, config, ...)
  - strong focus on API contracts (REST docs, cruddy APIs, lack of hypermedia, breaking API changes)
- modulith (restructuring your monolith):
  - let your bounded contexts fire events
  - invert the dependency between bounded contexts (dont do method invocation on other contexts, send out events)
  - you can use Spring Core ApplicationEvent or Spring Data DomainEvents with `@EventListener`
  - differences with monolith:
    - focus of domain logic has moved to aggregate
    - integration between bounded contexts is event based
    - inverted dependency between bounded contexts
- system of systems:
  - integration options: messaging or REST
  - events are published as messages in a central message broker (Kafka, RabbitMQ)
    - this is shared infrastructure
    - needs to be built for scale
    - knows everything about all the systems
    - just like with REST, you are coupled via message serialization format
    - PRO TIP: `@JsonPath("$.product.id")` annotation for message payload
  - when using REST only (to avoid central message broker):
    - publish local events in your local API
    - client of that API polls the API for changes in events (using offsets or timestamps)
    - we consider events as part of the state of the system (HTTP resources for events)
    - collections of events should be filterable by: event type, publication time, pagination, caching, ...
    - media types: JSON, HAL, Atom Feeds even (XML)
    - the client is totally under control of the size of the consistency gap (they decide how frequently they poll)
    - events from a given bounded context stays locally in that context
    - disadvantages: bigger concistency gap, doesnt scale as good
    - testability becomes much easier, easily debuggable
  - so discussion becomes question of distributed system vs decentralized system
- bounded contexts interaction
- what kind of consistency do we require
- how do apps behave in error situations
- how can apps evolve independently

## Tommy Ludwig: Observability with Spring based distributed systems

<span class="image left"><img class="p-image" alt="Tommy Ludwig" src="/img/spring-io-2018/tommy-ludwig.jpg"></span>

### Introduction

[Tommy](https://twitter.com/tommyludwig){:target="blank"}'s talk introduced three main pillars of observability: logging, metrics, and tracing.

Tommy explained that observability is achieved through a set of tools and practices that aim to turn data points and contexts into insights.
Observability is something you should care about as it provides a great experience for the users of your system and it builds confidence in production where failure **will** happen.
You ought to give yourself the tools you need in order to be a good owner in order to detect this failures as early as possible.
Mean time to recovery is key here.
He also quoted Werner Vogels's, the CEO of Amazon, "You build it, you run it" while also adding to it that you need to monitor it.

Within a Spring Boot project, we have access to Actuator and it is awesome.
It comes with a lot of goodies out of the box.
There is also [Spring Boot Admin](https://github.com/codecentric/spring-boot-admin){:target="_blank"} that makes it easy to access and use each instance's Actuator endpoints.

Distributed systems make observing them hard by design as a request spans multiple processes.
You therefore need to stitch these together in order to fully make sense of it.
There are also more points of failure and adding multiple instances of the same service, for scaling reasons, will only increase the monitoring complexity.

Tommy named three sides to observability:
* Logging
* Metrics
* Tracing

### Logging
Logs are request scoped, arbitrary messages that you want to find back later.
They are formatted to give you context via things such as logging levels and the timestamp.
The issue with logs is that they do not scale, concurrent requests intermingle logs, and searching through them can be cumbersome.
In order to tackle these issues you can make use of centralized logging while also adding a query capability to retrieve a collection of matching logs.
Within Spring Boot we can configure the logging via Spring Environment and via Actuator at runtime.
[Spring Cloud Sleuth](https://cloud.spring.io/spring-cloud-sleuth/){:target="_blank"} is useful to add a trace ID for request correlation.

### Metrics
Metrics aggregate time series data and have a bounded size.
You can slice these based on dimensions, tags and labels.
The main goal of metrics is to visualize and identify trends and deviations, and to raise alerts based on metric queries.
Some examples of metrics are: response time, the response's body size and memory consumed.
In order to properly measure all this, you need to set up a metrics backend to which all applications publish their metrics data.
In Spring Boot 2, [Micrometer](https://github.com/micrometer-metrics/micrometer){:target="_blank"} is introduced as its native metrics library.
Micrometer supports many metrics backends such as Atlas Datadog, Prometheus, SignalFX and Wavefront.
A lot of the instrumentation is auto-configured by Spring Boot and custom metrics are easy to add.
These are configurable via properties and common tags such as the application name, the instance, region, zone, and more.

### Tracing
Local tracing happens via the Actuator `/httptrace` endpoint and displays the latency data.
With distributed tracing you can go across process boundaries which is useful as metrics lack request context and as logs have a local context but limited distributed info.
You define the sample of how many request to trace yourself as you don't want to trace everything especially if you have a high load.
[Zipkin](https://zipkin.io){:target="_blank"} with its UI helps you to see the timing information visually and is a good tracing backend for Spring applications.
Using Spring Cloud Sleuth, it auto-configured the tracing instrumentation via [Zipkin's Brave](https://github.com/openzipkin/brave){:target="_blank"}.
Via properties you can configure things such as the sampling probability and whether certain endpoints should to be skipped.

### Correlation everywhere
Having set up all of these, you now have correlated logging, metrics and tracing across your system, and you can find the data from each based on identifiers.

### Observability cycle
If an issue produces itself we can take the following steps to troubleshoot and bandage the situation:
* The issue should've been reported via an alert or report
* We check the metrics of our system
* If needed, we check the tracing data
* If needed, we check the logs
* Based on the gathered information we can triage the issue and make adjustments to prevent a recurrence

### Key takeaways
System wide observability is crucial in distributed architectures.
The tools to help you with this exist and Spring makes it easy to integrate them in your system as the most common cases are covered out-of-the-box or easily configurable.
Use the right tool for the job and synergise across the different tools.


## Got triggered?

All talks were recorded by the Spring IO team. You can view them [here](https://www.youtube.com/). TODO Add correct URL

****
